{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 193,
     "status": "ok",
     "timestamp": 1628686856232,
     "user": {
      "displayName": "Datagram Intern",
      "photoUrl": "",
      "userId": "14028405452349474719"
     },
     "user_tz": -60
    },
    "id": "Qz8tjmTDT1Ce",
    "outputId": "d643e47a-7c54-4874-eb47-169d17e99e61"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "o4UTcnNPO6i_"
   },
   "source": [
    "### Importing the data from GDrive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 5259,
     "status": "ok",
     "timestamp": 1628686861850,
     "user": {
      "displayName": "Datagram Intern",
      "photoUrl": "",
      "userId": "14028405452349474719"
     },
     "user_tz": -60
    },
    "id": "c1kZ8zzqlhtF",
    "outputId": "9029efd7-570b-499a-8985-805ce1a312a9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading...\n",
      "From: https://drive.google.com/uc?id=1vm2r8WbmQTrSkPpldJipemRXnCMg0hiQ\n",
      "To: /content/clean_data.csv\n",
      "79.7MB [00:00, 171MB/s]\n"
     ]
    }
   ],
   "source": [
    "!gdown https://drive.google.com/uc?id=1vm2r8WbmQTrSkPpldJipemRXnCMg0hiQ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "executionInfo": {
     "elapsed": 1528,
     "status": "ok",
     "timestamp": 1628686863371,
     "user": {
      "displayName": "Datagram Intern",
      "photoUrl": "",
      "userId": "14028405452349474719"
     },
     "user_tz": -60
    },
    "id": "Bzbl4QqOlnR6"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv('/content/clean_data.csv') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 304
    },
    "executionInfo": {
     "elapsed": 535,
     "status": "ok",
     "timestamp": 1628686863903,
     "user": {
      "displayName": "Datagram Intern",
      "photoUrl": "",
      "userId": "14028405452349474719"
     },
     "user_tz": -60
    },
    "id": "gnqY5GnWlu0p",
    "outputId": "8741fb82-ebf7-4b26-921e-ad7d38a9f1d9"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>category_id</th>\n",
       "      <th>cname</th>\n",
       "      <th>pcname</th>\n",
       "      <th>pname</th>\n",
       "      <th>chain_id</th>\n",
       "      <th>word_count</th>\n",
       "      <th>clean</th>\n",
       "      <th>labels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>434</td>\n",
       "      <td>CHEWING GUMS</td>\n",
       "      <td>CONFISERIE</td>\n",
       "      <td>0000030034105 CONF SUCRE PCP+GUM MONDELEZ HOLL...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>9</td>\n",
       "      <td>conf sucre pcpgum mondelez hollywood chloroph...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>434</td>\n",
       "      <td>CHEWING GUMS</td>\n",
       "      <td>CONFISERIE</td>\n",
       "      <td>0000030034600 CONF SUCRE PCP+GUM MONDELEZ HOLL...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>9</td>\n",
       "      <td>conf sucre pcpgum mondelez hollywood hollywoo...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>434</td>\n",
       "      <td>CHEWING GUMS</td>\n",
       "      <td>CONFISERIE</td>\n",
       "      <td>0000030068834 CONF SUCRE PCP+GUM MONDELEZ HOLL...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10</td>\n",
       "      <td>conf sucre pcpgum mondelez hollywood  fresh p...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>434</td>\n",
       "      <td>CHEWING GUMS</td>\n",
       "      <td>CONFISERIE</td>\n",
       "      <td>0000030075214 CONF SUCRE PCP+GUM MONDELEZ HOLL...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10</td>\n",
       "      <td>conf sucre pcpgum mondelez hollywood green fr...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>435</td>\n",
       "      <td>CONFISERIES DE CHOCOLAT</td>\n",
       "      <td>CONFISERIE</td>\n",
       "      <td>0000040052496 CONF CHOC BARRES CHOC NESTLE KIT...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>13</td>\n",
       "      <td>conf choc barres choc nestle kit kat kit kat ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0  ...  labels\n",
       "0           0  ...       0\n",
       "1           1  ...       0\n",
       "2           2  ...       0\n",
       "3           3  ...       0\n",
       "4           4  ...       1\n",
       "\n",
       "[5 rows x 9 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 20,
     "status": "ok",
     "timestamp": 1628686863904,
     "user": {
      "displayName": "Datagram Intern",
      "photoUrl": "",
      "userId": "14028405452349474719"
     },
     "user_tz": -60
    },
    "id": "bbB5Wte9nz5X",
    "outputId": "bdd94b67-fb54-4994-e1ed-716c1a41b379"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 536437 entries, 0 to 536436\n",
      "Data columns (total 9 columns):\n",
      " #   Column       Non-Null Count   Dtype  \n",
      "---  ------       --------------   -----  \n",
      " 0   Unnamed: 0   536437 non-null  int64  \n",
      " 1   category_id  536437 non-null  int64  \n",
      " 2   cname        536437 non-null  object \n",
      " 3   pcname       536437 non-null  object \n",
      " 4   pname        536437 non-null  object \n",
      " 5   chain_id     476066 non-null  float64\n",
      " 6   word_count   536437 non-null  int64  \n",
      " 7   clean        536437 non-null  object \n",
      " 8   labels       536437 non-null  int64  \n",
      "dtypes: float64(1), int64(4), object(4)\n",
      "memory usage: 36.8+ MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 15,
     "status": "ok",
     "timestamp": 1628686863905,
     "user": {
      "displayName": "Datagram Intern",
      "photoUrl": "",
      "userId": "14028405452349474719"
     },
     "user_tz": -60
    },
    "id": "_yxpl3LFtBCo",
    "outputId": "153653d7-5892-4e96-e905-28a197f41555"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 •••class : CHEWING GUMS, text : conf sucre pcpgum mondelez hollywood chlorophyl permanent \n",
      "1 •••class : CHEWING GUMS, text : conf sucre pcpgum mondelez hollywood hollywood permanent \n",
      "2 •••class : CHEWING GUMS, text : conf sucre pcpgum mondelez hollywood  fresh permanent \n",
      "3 •••class : CHEWING GUMS, text : conf sucre pcpgum mondelez hollywood green fresh permanent \n",
      "4 •••class : CONFISERIES DE CHOCOLAT, text : conf choc barres choc nestle kit kat kit kat classique permanent \n",
      "5 •••class : CONFISERIES DE CHOCOLAT, text : conf choc small bites nestle smarties smarties permanent \n",
      "6 •••class : CONFISERIES DE CHOCOLAT, text : conf choc tablettes ferrero kinder kinder chocolat permanent \n",
      "7 •••class : CONFISERIES DE CHOCOLAT, text : conf choc small bites ferrero kinder kinder autres saisonnier \n",
      "8 •••class : CONFISERIES DE CHOCOLAT, text : conf choc small bites mars fab mms mms peanuts permanent \n",
      "9 •••class : BONBONS, SUCETTES ET CONFISERIE DE SUCRE, text : f sucre bonbons solinest werthers original werther s orig permanent \n",
      "10 •••class : BONBONS, SUCETTES ET CONFISERIE DE SUCRE, text : f sucre bonbons solinest werthers original werther s orig permanent \n",
      "11 •••class : BEERS, text :maisels weisse alcohol free weissbier  ml\n",
      "12 •••class : CONFISERIES DE CHOCOLAT, text : conf choc novelties nestle smarties smarties saisonnier \n",
      "13 •••class : BEERS, text :beck blue na  ow   box uk\n",
      "14 •••class : BISCUITS SECS, text : biscuits autres fabricants autres marques autres marques permanent \n",
      "15 •••class : BARRES CEREALIERES, text : cerealieres autres fabricants autres marques autres marques permanent \n",
      "16 •••class : FRUITS SECS, text : cerealieres autres fabricants autres marques autres marques permanent \n",
      "17 •••class : FRUITS SECS, text : cerealieres autres fabricants autres marques autres marques permanent \n",
      "18 •••class : BARRES CEREALIERES, text : cerealieres autres fabricants autres marques autres marques permanent \n",
      "19 •••class : BARRES CEREALIERES, text : cerealieres autres fabricants autres marques autres marques permanent \n",
      "20 •••class : CONFISERIES DE CHOCOLAT, text : barres choc autres fabricants autres marques autres marques permanent \n",
      "21 •••class : BISCUITS SECS, text : biscuits autres fabricants autres marques autres marques permanent \n",
      "22 •••class : CONFISERIES DE CHOCOLAT, text : barres choc autres fabricants autres marques autres marques permanent \n",
      "23 •••class : CONFISERIES DE CHOCOLAT, text : barres choc autres fabricants autres marques autres marques permanent \n",
      "24 •••class : CONFITURES, text : rtinables autres fabricants autres marques autres marques permanent \n",
      "25 •••class : CONFITURES, text : rtinables autres fabricants autres marques autres marques permanent \n",
      "26 •••class : CHEWING GUMS, text : conf sucre pcpgum wrigley airwaves airwaves permanent \n",
      "27 •••class : FRUITS SECS, text : cerealieres autres fabricants autres marques autres marques permanent \n",
      "28 •••class : FRUITS SECS, text : barres choc autres fabricants autres marques autres marques permanent \n",
      "29 •••class : BEERS, text :beck can   hic tra uk n\n",
      "30 •••class : GATEAUX, ROULES, PAINS D'EPICES ET NONNETTES, text : tionnelle autres fabricants autres marques autres marques permanent \n",
      "31 •••class : GOUTERS, text : er biscuits autres fabricants autres marques autres marques permanent \n",
      "32 •••class : BARRES CEREALIERES, text : cerealieres autres fabricants autres marques autres marques permanent \n",
      "33 •••class : CEREALES, text : dej cpac autres fabricants autres marques autres marques permanent \n",
      "34 •••class : BARRES CEREALIERES, text : cerealieres autres fabricants autres marques autres marques permanent \n",
      "35 •••class : FRUITS SECS, text : cerealieres autres fabricants autres marques autres marques permanent \n",
      "36 •••class : CHEWING GUMS, text : conf sucre pcpgum wrigley airwaves cafeine permanent \n",
      "37 •••class : BARRES CEREALIERES, text : cerealieres autres fabricants autres marques autres marques permanent \n",
      "38 •••class : CONFISERIES DE CHOCOLAT, text : conf choc novelties nestle smarties smarties saisonnier \n",
      "39 •••class : CONFISERIES DE CHOCOLAT, text : conf choc novelties nestle smarties smarties saisonnier \n",
      "40 •••class : FRUITS SECS, text : cerealieres autres fabricants autres marques autres marques permanent \n",
      "41 •••class : BONBONS, SUCETTES ET CONFISERIE DE SUCRE, text : conf sucre bonbons solinest chupa chups chupa chups permanent \n",
      "42 •••class : CONFISERIES DE CHOCOLAT, text : conf choc small bites mars fab mms mms peanuts saisonnier \n",
      "43 •••class : BISCUITS SALES, text :jacobs yildiz basique cheddar   std \n",
      "44 •••class : CONFITURES, text : rtinables autres fabricants autres marques autres marques permanent \n",
      "45 •••class : CONFITURES, text : rtinables autres fabricants autres marques autres marques permanent \n",
      "46 •••class : CHEWING GUMS, text : conf sucre pcpgum wrigley airwaves cafeine permanent \n",
      "47 •••class : CONFITURES, text : rtinables autres fabricants autres marques autres marques permanent \n",
      "48 •••class : CONFITURES, text : rtinables autres fabricants autres marques autres marques permanent \n",
      "49 •••class : BEERS, text :guinness original stout beer  ml\n",
      "50 •••class : BEERS, text :guinness draught stout beer  ml\n",
      "51 •••class : CONFITURES, text : petit dej tartinables f duerr  sons duerrs duerrs permanent \n",
      "52 •••class : CONFITURES, text : petit dej tartinables f duerr  sons duerrs duerrs permanent \n",
      "53 •••class : MOUCHOIRS EN PAPIER, text :kc kleenxbalsam mouchrsenppr balsam s  paquet plastq\n",
      "54 •••class : CHEWING GUMS, text : conf sucre pcpgum mondelez hollywood mini mints permanent \n",
      "55 •••class : BONBONS, SUCETTES ET CONFISERIE DE SUCRE, text : conf sucre pcpgum mondelez hollywood mini mints permanent \n",
      "56 •••class : CHEWING GUMS, text : conf sucre pcpgum mondelez hollywood mini mints permanent \n",
      "57 •••class : CHEWING GUMS, text : conf sucre pcpgum mondelez hollywood mini mints permanent \n",
      "58 •••class : CHEWING GUMS, text : conf sucre pcpgum mondelez hollywood mini mints permanent \n",
      "59 •••class : BONBONS, SUCETTES ET CONFISERIE DE SUCRE, text : conf sucre pcpgum mondelez la vosgiene seve de pin permanent \n",
      "60 •••class : BONBONS, SUCETTES ET CONFISERIE DE SUCRE, text : conf sucre pcpgum mondelez la vosgiene vosgienne permanent \n",
      "61 •••class : PATES A TARTINER, text : petit dej tartinables ferrero nutella nutella permanent \n",
      "62 •••class : CONFISERIES DE CHOCOLAT, text : conf choc novelties nestle smarties smarties saisonnier \n",
      "63 •••class : CONFISERIES DE CHOCOLAT, text : conf choc novelties nestle smarties smarties saisonnier \n",
      "64 •••class : CONFISERIES DE CHOCOLAT, text : conf choc novelties nestle smarties smarties saisonnier \n",
      "65 •••class : CONFISERIES DE CHOCOLAT, text : conf choc novelties nestle smarties smarties saisonnier \n",
      "66 •••class : BEERS, text :corona extra ow   box mxuk wb\n",
      "67 •••class : BEERS, text :mode espe ow   n\n",
      "68 •••class : BEERS, text :corona ex ow    bucket\n",
      "69 •••class : CONFISERIES DE CHOCOLAT, text : conf choc tablettes mondelez toblerone toblerone permanent \n",
      "70 •••class : CONFISERIES DE CHOCOLAT, text : conf choc tablettes mondelez toblerone toblerone permanent \n",
      "71 •••class : CONFISERIES DE CHOCOLAT, text : oc pralines autres fabricants autres marques autres marques permanent \n"
     ]
    }
   ],
   "source": [
    "for h,(i , j) in enumerate(zip(df['cname'],df['clean'])):\n",
    "  print(\"{} •••class : {}, text :{}\".format(h,i,j))\n",
    "  if h>70:\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 2585,
     "status": "ok",
     "timestamp": 1628686866482,
     "user": {
      "displayName": "Datagram Intern",
      "photoUrl": "",
      "userId": "14028405452349474719"
     },
     "user_tz": -60
    },
    "id": "baBtG43WuQvi",
    "outputId": "406bc79f-7732-4c64-bf0a-7f3687349c9f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading...\n",
      "From: https://drive.google.com/uc?id=1Id1Zxjj3v0ujhZXlTgb6lItUjyRw_zpb\n",
      "To: /content/fmcg_cat.csv\n",
      "55.0MB [00:00, 175MB/s] \n"
     ]
    }
   ],
   "source": [
    "!gdown https://drive.google.com/uc?id=1Id1Zxjj3v0ujhZXlTgb6lItUjyRw_zpb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "executionInfo": {
     "elapsed": 918,
     "status": "ok",
     "timestamp": 1628686867396,
     "user": {
      "displayName": "Datagram Intern",
      "photoUrl": "",
      "userId": "14028405452349474719"
     },
     "user_tz": -60
    },
    "id": "KOVeMU8euXjH"
   },
   "outputs": [],
   "source": [
    "non_clean_data = pd.read_csv('/content/fmcg_cat.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 19,
     "status": "ok",
     "timestamp": 1628686867397,
     "user": {
      "displayName": "Datagram Intern",
      "photoUrl": "",
      "userId": "14028405452349474719"
     },
     "user_tz": -60
    },
    "id": "yzAwXjXGufg-",
    "outputId": "578ac9c9-3ae9-43c1-f861-99ac785f9404"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0•••• class : CHEWING GUMS, text :0000030034105 CONF SUCRE PCP+GUM MONDELEZ HOLLYWOOD CHLOROPHYL PERMANENT 1/20D/28G/28\n",
      "1•••• class : CHEWING GUMS, text :0000030034600 CONF SUCRE PCP+GUM MONDELEZ HOLLYWOOD HOLLYWOOD PERMANENT 1/11T/31G/31\n",
      "2•••• class : CHEWING GUMS, text :0000030068834 CONF SUCRE PCP+GUM MONDELEZ HOLLYWOOD 2 FRESH PERMANENT 1/10D/22G/22\n",
      "3•••• class : CHEWING GUMS, text :0000030075214 CONF SUCRE PCP+GUM MONDELEZ HOLLYWOOD GREEN FRESH PERMANENT 1/60D/87G/87\n",
      "4•••• class : CONFISERIES DE CHOCOLAT, text :0000040052496 CONF CHOC BARRES CHOC NESTLE KIT KAT KIT KAT CLASSIQUE PERMANENT 1/3/41.5G/124\n",
      "5•••• class : CONFISERIES DE CHOCOLAT, text :0000040056470 CONF CHOC SMALL BITES NESTLE SMARTIES SMARTIES PERMANENT 1/5/38G/190\n",
      "6•••• class : CONFISERIES DE CHOCOLAT, text :0000040084701 CONF CHOC TABLETTES FERRERO KINDER KINDER CHOCOLAT PERMANENT 1/8/12.5G/100\n",
      "7•••• class : CONFISERIES DE CHOCOLAT, text :0000040084749 CONF CHOC SMALL BITES FERRERO KINDER KINDER AUTRES SAISONNIER 1/*/79G/79\n",
      "8•••• class : CONFISERIES DE CHOCOLAT, text :0000040111445 CONF CHOC SMALL BITES MARS FAB M&M's M&M's PEANUTS PERMANENT 1/1/45G/45\n",
      "9•••• class : BONBONS, SUCETTES ET CONFISERIE DE SUCRE, text :0000040144108 F SUCRE BONBONS SOLINEST WERTHERS ORIGINAL WERTHER S ORIG PERMANENT 1/*/300G/300\n",
      "10•••• class : BONBONS, SUCETTES ET CONFISERIE DE SUCRE, text :0000040144283 F SUCRE BONBONS SOLINEST WERTHERS ORIGINAL WERTHER S ORIG PERMANENT 1/*/175G/175\n",
      "11•••• class : BEERS, text :Maisel's Weisse Alcohol Free Weissbier 500 ML\n",
      "12•••• class : WHISKY, text :40234236\n",
      "13•••• class : WHISKY, text :40241623\n",
      "14•••• class : WHISKY, text :40249339\n",
      "15•••• class : WHISKY, text :40249735\n",
      "16•••• class : WHISKY, text :40287546\n",
      "17•••• class : WHISKY, text :40291673\n",
      "18•••• class : CONFISERIES DE CHOCOLAT, text :0000041007563 CONF CHOC NOVELTIES NESTLE SMARTIES SMARTIES SAISONNIER 1/*/85G/85\n",
      "19•••• class : BEERS, text :BECK BLUE NA 0,0 OW 24 0,275L BOX UK\n",
      "20•••• class : BISCUITS SECS, text :0000042080367 BISCUITS AUTRES FABRICANTS AUTRES MARQUES AUTRES MARQUES PERMANENT 1/*/150G/150\n",
      "21•••• class : BARRES CEREALIERES, text :0000042096184 CEREALIERES AUTRES FABRICANTS AUTRES MARQUES AUTRES MARQUES PERMANENT 1/1/40G/*\n",
      "22•••• class : FRUITS SECS, text :0000042096191 CEREALIERES AUTRES FABRICANTS AUTRES MARQUES AUTRES MARQUES PERMANENT 1/1/40G/*\n",
      "23•••• class : FRUITS SECS, text :0000042096221 CEREALIERES AUTRES FABRICANTS AUTRES MARQUES AUTRES MARQUES PERMANENT 1/1/40G/*\n",
      "24•••• class : BARRES CEREALIERES, text :0000042100454 CEREALIERES AUTRES FABRICANTS AUTRES MARQUES AUTRES MARQUES PERMANENT 1/1/75G/*\n",
      "25•••• class : BARRES CEREALIERES, text :0000042100478 CEREALIERES AUTRES FABRICANTS AUTRES MARQUES AUTRES MARQUES PERMANENT 1/1/75G/*\n",
      "26•••• class : CONFISERIES DE CHOCOLAT, text :0000042100522 BARRES CHOC AUTRES FABRICANTS AUTRES MARQUES AUTRES MARQUES PERMANENT 1/2/40G/40\n",
      "27•••• class : BISCUITS SECS, text :0000042104520 BISCUITS AUTRES FABRICANTS AUTRES MARQUES AUTRES MARQUES PERMANENT 1/*/150G/150\n",
      "28•••• class : CONFISERIES DE CHOCOLAT, text :0000042143956 BARRES CHOC AUTRES FABRICANTS AUTRES MARQUES AUTRES MARQUES PERMANENT 1/2/40G/40\n",
      "29•••• class : CONFISERIES DE CHOCOLAT, text :0000042178149 BARRES CHOC AUTRES FABRICANTS AUTRES MARQUES AUTRES MARQUES PERMANENT 1/1/35G/35\n",
      "30•••• class : CONFITURES, text :0000042182818 RTINABLES AUTRES FABRICANTS AUTRES MARQUES AUTRES MARQUES PERMANENT 1/*/200G/200\n",
      "31•••• class : CONFITURES, text :0000042204459 RTINABLES AUTRES FABRICANTS AUTRES MARQUES AUTRES MARQUES PERMANENT 1/*/200G/200\n",
      "32•••• class : CHEWING GUMS, text :0000042211990 CONF SUCRE PCP+GUM WRIGLEY AIRWAVES AIRWAVES PERMANENT 1/10D/14G/14\n",
      "33•••• class : FRUITS SECS, text :0000042214366 CEREALIERES AUTRES FABRICANTS AUTRES MARQUES AUTRES MARQUES PERMANENT 1/1/75G/*\n",
      "34•••• class : FRUITS SECS, text :0000042214458 BARRES CHOC AUTRES FABRICANTS AUTRES MARQUES AUTRES MARQUES PERMANENT 1/1/40G/40\n",
      "35•••• class : BEERS, text :BECK CAN 6X4 0,5L HIC TRA UK N\n",
      "36•••• class : GATEAUX, ROULES, PAINS D'EPICES ET NONNETTES, text :0000042242697 TIONNELLE AUTRES FABRICANTS AUTRES MARQUES AUTRES MARQUES PERMANENT 1/1/125G/125\n",
      "37•••• class : GOUTERS, text :0000042247111 ER BISCUITS AUTRES FABRICANTS AUTRES MARQUES AUTRES MARQUES PERMANENT 1/*/90G/90\n",
      "38•••• class : BARRES CEREALIERES, text :0000042279655 CEREALIERES AUTRES FABRICANTS AUTRES MARQUES AUTRES MARQUES PERMANENT 1/1/75G/*\n",
      "39•••• class : CEREALES, text :0000042305156 DEJ CPAC AUTRES FABRICANTS AUTRES MARQUES AUTRES MARQUES PERMANENT 1/1/450G/450\n",
      "40•••• class : BARRES CEREALIERES, text :0000042305880 CEREALIERES AUTRES FABRICANTS AUTRES MARQUES AUTRES MARQUES PERMANENT 1/1/75G/*\n",
      "41•••• class : FRUITS SECS, text :0000042305897 CEREALIERES AUTRES FABRICANTS AUTRES MARQUES AUTRES MARQUES PERMANENT 1/1/75G/*\n",
      "42•••• class : CHEWING GUMS, text :0000042307181 CONF SUCRE PCP+GUM WRIGLEY AIRWAVES CAFEINE PERMANENT 1/8D/19G/19\n",
      "43•••• class : BARRES CEREALIERES, text :0000042328209 CEREALIERES AUTRES FABRICANTS AUTRES MARQUES AUTRES MARQUES PERMANENT 1/1/30G/*\n",
      "44•••• class : CONFISERIES DE CHOCOLAT, text :0000042370291 CONF CHOC NOVELTIES NESTLE SMARTIES SMARTIES SAISONNIER 1/*/85G/85\n",
      "45•••• class : CONFISERIES DE CHOCOLAT, text :0000042370307 CONF CHOC NOVELTIES NESTLE SMARTIES SMARTIES SAISONNIER 1/*/85G/85\n",
      "46•••• class : FRUITS SECS, text :0000042390275 CEREALIERES AUTRES FABRICANTS AUTRES MARQUES AUTRES MARQUES PERMANENT 1/1/40G/*\n",
      "47•••• class : WHISKY, text :45480768\n",
      "48•••• class : BONBONS, SUCETTES ET CONFISERIE DE SUCRE, text :0000049814521 CONF SUCRE BONBONS SOLINEST CHUPA CHUPS CHUPA CHUPS PERMANENT 1/1S/12G/12\n",
      "49•••• class : CONFISERIES DE CHOCOLAT, text :0000050159871 CONF CHOC SMALL BITES MARS FAB M&M's M&M's PEANUTS SAISONNIER 1/1/45G/45\n",
      "50•••• class : BISCUITS SALES, text :JACOBS (YILDIZ) BASIQUE CHEDDAR 1X 150 STD 0000050168101\n",
      "51•••• class : CONFITURES, text :0000050172474 RTINABLES AUTRES FABRICANTS AUTRES MARQUES AUTRES MARQUES PERMANENT 1/*/340G/340\n",
      "52•••• class : CONFITURES, text :0000050172672 RTINABLES AUTRES FABRICANTS AUTRES MARQUES AUTRES MARQUES PERMANENT 1/*/411G/411\n",
      "53•••• class : CHEWING GUMS, text :0000050173051 CONF SUCRE PCP+GUM WRIGLEY AIRWAVES CAFEINE PERMANENT 1/8D/19G/19\n",
      "54•••• class : CONFITURES, text :0000050183357 RTINABLES AUTRES FABRICANTS AUTRES MARQUES AUTRES MARQUES PERMANENT 1/*/454G/454\n",
      "55•••• class : CONFITURES, text :0000050183364 RTINABLES AUTRES FABRICANTS AUTRES MARQUES AUTRES MARQUES PERMANENT 1/*/454G/454\n",
      "56•••• class : BEERS, text :Guinness Original Stout Beer 4X440 ML\n",
      "57•••• class : BEERS, text :Guinness Draught Stout Beer 4X440 ML\n",
      "58•••• class : CONFITURES, text :0000050214211 PETIT DEJ TARTINABLES F. DUERR & SONS DUERRS DUERRS PERMANENT 1/*/454G/454\n",
      "59•••• class : CONFITURES, text :0000050214228 PETIT DEJ TARTINABLES F. DUERR & SONS DUERRS DUERRS PERMANENT 1/*/454G/454\n",
      "60•••• class : MOUCHOIRS EN PAPIER, text :KC KLEENX-BALSAM MOUCHRS-EN-PPR BALSAM 9'S X1 PAQUET PLASTQ\n",
      "61•••• class : WHISKY, text :53313560\n",
      "62•••• class : CHEWING GUMS, text :0000057023373 CONF SUCRE PCP+GUM MONDELEZ HOLLYWOOD MINI MINTS PERMANENT 1/*/12.5G/12\n",
      "63•••• class : BONBONS, SUCETTES ET CONFISERIE DE SUCRE, text :0000057023397 CONF SUCRE PCP+GUM MONDELEZ HOLLYWOOD MINI MINTS PERMANENT 1/*/12.5G/12\n",
      "64•••• class : CHEWING GUMS, text :0000057023397 CONF SUCRE PCP+GUM MONDELEZ HOLLYWOOD MINI MINTS PERMANENT 1/*/12.5G/12\n",
      "65•••• class : CHEWING GUMS, text :0000057023618 CONF SUCRE PCP+GUM MONDELEZ HOLLYWOOD MINI MINTS PERMANENT 1/*/12.5G/12\n",
      "66•••• class : CHEWING GUMS, text :0000057023632 CONF SUCRE PCP+GUM MONDELEZ HOLLYWOOD MINI MINTS PERMANENT 1/*/12.5G/12\n",
      "67•••• class : BONBONS, SUCETTES ET CONFISERIE DE SUCRE, text :0000057026749 CONF SUCRE PCP+GUM MONDELEZ LA VOSGIENE SEVE DE PIN PERMANENT 1/*/36G/36\n",
      "68•••• class : BONBONS, SUCETTES ET CONFISERIE DE SUCRE, text :0000057026756 CONF SUCRE PCP+GUM MONDELEZ LA VOSGIENE VOSGIENNE PERMANENT 1/*/36G/36\n",
      "69•••• class : PATES A TARTINER, text :0000059032823 PETIT DEJ TARTINABLES FERRERO NUTELLA NUTELLA PERMANENT 1/*/630G/630\n",
      "70•••• class : CONFISERIES DE CHOCOLAT, text :0000059944829 CONF CHOC NOVELTIES NESTLE SMARTIES SMARTIES SAISONNIER 1/*/100G/100\n",
      "71•••• class : CONFISERIES DE CHOCOLAT, text :0000059944836 CONF CHOC NOVELTIES NESTLE SMARTIES SMARTIES SAISONNIER 1/*/100G/100\n"
     ]
    }
   ],
   "source": [
    "for h,(i , j) in enumerate(zip(non_clean_data['cname'],non_clean_data['pname'])):\n",
    "  print(\"{}•••• class : {}, text :{}\".format(h,i,j))\n",
    "  if h>70:\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "executionInfo": {
     "elapsed": 17,
     "status": "ok",
     "timestamp": 1628686867398,
     "user": {
      "displayName": "Datagram Intern",
      "photoUrl": "",
      "userId": "14028405452349474719"
     },
     "user_tz": -60
    },
    "id": "w4WkFQkRwgRQ"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Mf1HZ5IJmGHs"
   },
   "source": [
    "## preprocessing the input data cname,pcname"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 16,
     "status": "ok",
     "timestamp": 1628686867398,
     "user": {
      "displayName": "Datagram Intern",
      "photoUrl": "",
      "userId": "14028405452349474719"
     },
     "user_tz": -60
    },
    "id": "B3RRsBG7m0H2",
    "outputId": "e19566f2-c2e9-4518-846a-52d6d6549c83"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Unnamed: 0         0\n",
       "category_id        0\n",
       "cname              0\n",
       "pcname             0\n",
       "pname              0\n",
       "chain_id       60371\n",
       "word_count         0\n",
       "clean              0\n",
       "labels             0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 10,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "executionInfo": {
     "elapsed": 9,
     "status": "ok",
     "timestamp": 1628686867399,
     "user": {
      "displayName": "Datagram Intern",
      "photoUrl": "",
      "userId": "14028405452349474719"
     },
     "user_tz": -60
    },
    "id": "sk_IUrG5m0Py"
   },
   "outputs": [],
   "source": [
    "df.dropna(subset=['clean'],inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 310,
     "status": "ok",
     "timestamp": 1628686867701,
     "user": {
      "displayName": "Datagram Intern",
      "photoUrl": "",
      "userId": "14028405452349474719"
     },
     "user_tz": -60
    },
    "id": "yFO0KtBSm0TD",
    "outputId": "ab12512b-48b0-4970-c848-566fb6811b03"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Unnamed: 0         0\n",
       "category_id        0\n",
       "cname              0\n",
       "pcname             0\n",
       "pname              0\n",
       "chain_id       60371\n",
       "word_count         0\n",
       "clean              0\n",
       "labels             0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 12,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "executionInfo": {
     "elapsed": 5,
     "status": "ok",
     "timestamp": 1628686867701,
     "user": {
      "displayName": "Datagram Intern",
      "photoUrl": "",
      "userId": "14028405452349474719"
     },
     "user_tz": -60
    },
    "id": "KjqQH-WinLOD"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "executionInfo": {
     "elapsed": 6,
     "status": "ok",
     "timestamp": 1628686867702,
     "user": {
      "displayName": "Datagram Intern",
      "photoUrl": "",
      "userId": "14028405452349474719"
     },
     "user_tz": -60
    },
    "id": "8TVty_nslzl_"
   },
   "outputs": [],
   "source": [
    "df['cname'] = df['cname'].apply(lambda x:x.replace(' ',\"_\"))\n",
    "df['pcname'] = df['pcname'].apply(lambda x:x.replace(' ',\"_\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 237,
     "status": "ok",
     "timestamp": 1628686867934,
     "user": {
      "displayName": "Datagram Intern",
      "photoUrl": "",
      "userId": "14028405452349474719"
     },
     "user_tz": -60
    },
    "id": "v9xUYphFoE52",
    "outputId": "19084b95-2546-4e46-bce0-dea608a43f88"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SHAMPOOINGS                            17208\n",
       "SAUCISSERIE_ET_CHARCUTERIE_TRANCHEE    13975\n",
       "SOINS_DU_VISAGE                        12689\n",
       "ALIMENTS_BEBE                          12541\n",
       "FRESH_DESSERTS                          9150\n",
       "                                       ...  \n",
       "ARTICHAUTS                                 6\n",
       "CHATAIGNES                                 4\n",
       "MAINTIEN_ET_CONTENTION                     4\n",
       "EPINARDS                                   3\n",
       "LEGUMES_EXOTIQUES                          2\n",
       "Name: cname, Length: 334, dtype: int64"
      ]
     },
     "execution_count": 14,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.cname.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 12,
     "status": "ok",
     "timestamp": 1628686867934,
     "user": {
      "displayName": "Datagram Intern",
      "photoUrl": "",
      "userId": "14028405452349474719"
     },
     "user_tz": -60
    },
    "id": "COIEx6FmoL8Q",
    "outputId": "c0272311-34c5-44f4-b7e6-a156b453afc2"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "HYGIENE_CORPORELLE_ET_SOINS_BEAUTE    57656\n",
       "PETITS_DEJEUNERS                      31453\n",
       "HYGIENE_CHEVEUX                       28412\n",
       "CHARCUTERIE                           25370\n",
       "FRESH_DAIRY_PRODUCTS                  21697\n",
       "                                      ...  \n",
       "CIDERS                                  361\n",
       "PARAPHARMACIE                           119\n",
       "AMPOULES_PILES                          106\n",
       "SPORT                                    53\n",
       "MAITIEN_ARTICULAIRE_ET_SEMELLES          41\n",
       "Name: pcname, Length: 64, dtype: int64"
      ]
     },
     "execution_count": 15,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.pcname.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "executionInfo": {
     "elapsed": 8,
     "status": "ok",
     "timestamp": 1628686867935,
     "user": {
      "displayName": "Datagram Intern",
      "photoUrl": "",
      "userId": "14028405452349474719"
     },
     "user_tz": -60
    },
    "id": "lyZxLGJB9HxZ"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "executionInfo": {
     "elapsed": 3838,
     "status": "ok",
     "timestamp": 1628686871766,
     "user": {
      "displayName": "Datagram Intern",
      "photoUrl": "",
      "userId": "14028405452349474719"
     },
     "user_tz": -60
    },
    "id": "pqBL3ECEoR88"
   },
   "outputs": [],
   "source": [
    "df.to_csv('/content/drive/MyDrive/seq2seq model/clean_seq2seq.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "executionInfo": {
     "elapsed": 20,
     "status": "ok",
     "timestamp": 1628686871767,
     "user": {
      "displayName": "Datagram Intern",
      "photoUrl": "",
      "userId": "14028405452349474719"
     },
     "user_tz": -60
    },
    "id": "KQ1wsAO9_ThN"
   },
   "outputs": [],
   "source": [
    "df['output_data']=df['pcname']+\" \"+df['cname']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 371
    },
    "executionInfo": {
     "elapsed": 28,
     "status": "ok",
     "timestamp": 1628686871776,
     "user": {
      "displayName": "Datagram Intern",
      "photoUrl": "",
      "userId": "14028405452349474719"
     },
     "user_tz": -60
    },
    "id": "4b7boLCw_T9A",
    "outputId": "fccac7ed-3cb2-4be6-9d4d-c9fce69dfa63"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>category_id</th>\n",
       "      <th>cname</th>\n",
       "      <th>pcname</th>\n",
       "      <th>pname</th>\n",
       "      <th>chain_id</th>\n",
       "      <th>word_count</th>\n",
       "      <th>clean</th>\n",
       "      <th>labels</th>\n",
       "      <th>output_data</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>434</td>\n",
       "      <td>CHEWING_GUMS</td>\n",
       "      <td>CONFISERIE</td>\n",
       "      <td>0000030034105 CONF SUCRE PCP+GUM MONDELEZ HOLL...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>9</td>\n",
       "      <td>conf sucre pcpgum mondelez hollywood chloroph...</td>\n",
       "      <td>0</td>\n",
       "      <td>CONFISERIE CHEWING_GUMS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>434</td>\n",
       "      <td>CHEWING_GUMS</td>\n",
       "      <td>CONFISERIE</td>\n",
       "      <td>0000030034600 CONF SUCRE PCP+GUM MONDELEZ HOLL...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>9</td>\n",
       "      <td>conf sucre pcpgum mondelez hollywood hollywoo...</td>\n",
       "      <td>0</td>\n",
       "      <td>CONFISERIE CHEWING_GUMS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>434</td>\n",
       "      <td>CHEWING_GUMS</td>\n",
       "      <td>CONFISERIE</td>\n",
       "      <td>0000030068834 CONF SUCRE PCP+GUM MONDELEZ HOLL...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10</td>\n",
       "      <td>conf sucre pcpgum mondelez hollywood  fresh p...</td>\n",
       "      <td>0</td>\n",
       "      <td>CONFISERIE CHEWING_GUMS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>434</td>\n",
       "      <td>CHEWING_GUMS</td>\n",
       "      <td>CONFISERIE</td>\n",
       "      <td>0000030075214 CONF SUCRE PCP+GUM MONDELEZ HOLL...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10</td>\n",
       "      <td>conf sucre pcpgum mondelez hollywood green fr...</td>\n",
       "      <td>0</td>\n",
       "      <td>CONFISERIE CHEWING_GUMS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>435</td>\n",
       "      <td>CONFISERIES_DE_CHOCOLAT</td>\n",
       "      <td>CONFISERIE</td>\n",
       "      <td>0000040052496 CONF CHOC BARRES CHOC NESTLE KIT...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>13</td>\n",
       "      <td>conf choc barres choc nestle kit kat kit kat ...</td>\n",
       "      <td>1</td>\n",
       "      <td>CONFISERIE CONFISERIES_DE_CHOCOLAT</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0  category_id  ... labels                         output_data\n",
       "0           0          434  ...      0             CONFISERIE CHEWING_GUMS\n",
       "1           1          434  ...      0             CONFISERIE CHEWING_GUMS\n",
       "2           2          434  ...      0             CONFISERIE CHEWING_GUMS\n",
       "3           3          434  ...      0             CONFISERIE CHEWING_GUMS\n",
       "4           4          435  ...      1  CONFISERIE CONFISERIES_DE_CHOCOLAT\n",
       "\n",
       "[5 rows x 10 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "executionInfo": {
     "elapsed": 309,
     "status": "ok",
     "timestamp": 1628686872059,
     "user": {
      "displayName": "Datagram Intern",
      "photoUrl": "",
      "userId": "14028405452349474719"
     },
     "user_tz": -60
    },
    "id": "FyYmc6L3_UFu"
   },
   "outputs": [],
   "source": [
    "df['output_data'] = df['output_data'].apply(lambda x:x.lower())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 6,
     "status": "ok",
     "timestamp": 1628686872059,
     "user": {
      "displayName": "Datagram Intern",
      "photoUrl": "",
      "userId": "14028405452349474719"
     },
     "user_tz": -60
    },
    "id": "x9ZS9Dvc_UIH",
    "outputId": "a44757a6-1e5d-4521-999a-f2ae2f39cc7b"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0               confiserie chewing_gums\n",
       "1               confiserie chewing_gums\n",
       "2               confiserie chewing_gums\n",
       "3               confiserie chewing_gums\n",
       "4    confiserie confiseries_de_chocolat\n",
       "Name: output_data, dtype: object"
      ]
     },
     "execution_count": 20,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['output_data'].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DiiPLFT3ANuL"
   },
   "source": [
    "## Preprocessing the output and the input data and creating the input for the teacher forcing (training the decoder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "executionInfo": {
     "elapsed": 5900,
     "status": "ok",
     "timestamp": 1628686877957,
     "user": {
      "displayName": "Datagram Intern",
      "photoUrl": "",
      "userId": "14028405452349474719"
     },
     "user_tz": -60
    },
    "id": "pzsTBIrtpIeH"
   },
   "outputs": [],
   "source": [
    "import os, sys\n",
    "\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input, Dense, Embedding, \\\n",
    "  Bidirectional, RepeatVector, Concatenate, Activation, Dot, Lambda ,LSTM\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.layers import Softmax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "executionInfo": {
     "elapsed": 10,
     "status": "ok",
     "timestamp": 1628686877958,
     "user": {
      "displayName": "Datagram Intern",
      "photoUrl": "",
      "userId": "14028405452349474719"
     },
     "user_tz": -60
    },
    "id": "V-oVrMH3xbd8"
   },
   "outputs": [],
   "source": [
    "# config\n",
    "BATCH_SIZE = 512\n",
    "EPOCHS = 2\n",
    "LATENT_DIM = 1024\n",
    "LATENT_DIM_DECODER = 1024 \n",
    "MAX_SEQUENCE_LENGTH = 100\n",
    "MAX_NUM_WORDS = 60000\n",
    "EMBEDDING_DIM = 512"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "executionInfo": {
     "elapsed": 9,
     "status": "ok",
     "timestamp": 1628686877958,
     "user": {
      "displayName": "Datagram Intern",
      "photoUrl": "",
      "userId": "14028405452349474719"
     },
     "user_tz": -60
    },
    "id": "FsKkUMCS-TAu"
   },
   "outputs": [],
   "source": [
    "# Where we will store the data\n",
    "input_texts = [] # sentence in original language\n",
    "target_texts = [] # sentence in target language output_data + <eos>\n",
    "target_texts_inputs = [] # inputs for teacher forcing target text as input (<sos> + sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "executionInfo": {
     "elapsed": 8,
     "status": "ok",
     "timestamp": 1628686877958,
     "user": {
      "displayName": "Datagram Intern",
      "photoUrl": "",
      "userId": "14028405452349474719"
     },
     "user_tz": -60
    },
    "id": "0fS7D0cs-ZSV"
   },
   "outputs": [],
   "source": [
    "input_texts = list(df['clean'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 9,
     "status": "ok",
     "timestamp": 1628686877959,
     "user": {
      "displayName": "Datagram Intern",
      "photoUrl": "",
      "userId": "14028405452349474719"
     },
     "user_tz": -60
    },
    "id": "HJOvTVu4Bdvv",
    "outputId": "cb35db50-2b87-4a7b-c2bb-e98edeadb981"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[' conf sucre pcpgum mondelez hollywood chlorophyl permanent ',\n",
       " ' conf sucre pcpgum mondelez hollywood hollywood permanent ',\n",
       " ' conf sucre pcpgum mondelez hollywood  fresh permanent ']"
      ]
     },
     "execution_count": 25,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_texts[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "executionInfo": {
     "elapsed": 335,
     "status": "ok",
     "timestamp": 1628686878289,
     "user": {
      "displayName": "Datagram Intern",
      "photoUrl": "",
      "userId": "14028405452349474719"
     },
     "user_tz": -60
    },
    "id": "nYb3uW9b-6nK"
   },
   "outputs": [],
   "source": [
    "target_texts = list(df['output_data']+\" <eos>\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 13,
     "status": "ok",
     "timestamp": 1628686878290,
     "user": {
      "displayName": "Datagram Intern",
      "photoUrl": "",
      "userId": "14028405452349474719"
     },
     "user_tz": -60
    },
    "id": "lFAVpkwgBp2w",
    "outputId": "b6fb5c89-7408-4d11-f837-56afe5b81555"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['biscuiterie_sucree barres_cerealieres <eos>',\n",
       " 'biscuiterie_sucree barres_cerealieres <eos>']"
      ]
     },
     "execution_count": 27,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target_texts[18:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "executionInfo": {
     "elapsed": 11,
     "status": "ok",
     "timestamp": 1628686878290,
     "user": {
      "displayName": "Datagram Intern",
      "photoUrl": "",
      "userId": "14028405452349474719"
     },
     "user_tz": -60
    },
    "id": "UdvpQEpL-6sW"
   },
   "outputs": [],
   "source": [
    "target_texts_inputs = list(\"<sos> \"+df['output_data'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 11,
     "status": "ok",
     "timestamp": 1628686878291,
     "user": {
      "displayName": "Datagram Intern",
      "photoUrl": "",
      "userId": "14028405452349474719"
     },
     "user_tz": -60
    },
    "id": "J8RpZehBBucr",
    "outputId": "65b748c0-02e4-4bef-94e1-a0628832f108"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['<sos> biscuiterie_sucree barres_cerealieres',\n",
       " '<sos> biscuiterie_sucree barres_cerealieres']"
      ]
     },
     "execution_count": 29,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target_texts_inputs[18:20]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LBX9IHs9B_85"
   },
   "source": [
    "## Building the tokenizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nkK_8wpwCI-Q"
   },
   "source": [
    "### building the input tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 4029,
     "status": "ok",
     "timestamp": 1628686882314,
     "user": {
      "displayName": "Datagram Intern",
      "photoUrl": "",
      "userId": "14028405452349474719"
     },
     "user_tz": -60
    },
    "id": "tf9rZ07IthWl",
    "outputId": "9c8df5de-7bec-40a5-bba2-3fbabab86976"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: transformers in /usr/local/lib/python3.7/dist-packages (4.9.2)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (2019.12.20)\n",
      "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from transformers) (4.6.1)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers) (3.0.12)\n",
      "Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from transformers) (21.0)\n",
      "Requirement already satisfied: tokenizers<0.11,>=0.10.1 in /usr/local/lib/python3.7/dist-packages (from transformers) (0.10.3)\n",
      "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers) (4.41.1)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.7/dist-packages (from transformers) (5.4.1)\n",
      "Requirement already satisfied: huggingface-hub==0.0.12 in /usr/local/lib/python3.7/dist-packages (from transformers) (0.0.12)\n",
      "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (1.19.5)\n",
      "Requirement already satisfied: sacremoses in /usr/local/lib/python3.7/dist-packages (from transformers) (0.0.45)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers) (2.23.0)\n",
      "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from huggingface-hub==0.0.12->transformers) (3.7.4.3)\n",
      "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->transformers) (2.4.7)\n",
      "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->transformers) (3.5.0)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2.10)\n",
      "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (3.0.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2021.5.30)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (1.24.3)\n",
      "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.15.0)\n",
      "Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (7.1.2)\n",
      "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.0.1)\n"
     ]
    }
   ],
   "source": [
    "!pip install transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "executionInfo": {
     "elapsed": 12,
     "status": "ok",
     "timestamp": 1628686882315,
     "user": {
      "displayName": "Datagram Intern",
      "photoUrl": "",
      "userId": "14028405452349474719"
     },
     "user_tz": -60
    },
    "id": "w-aQBt3jQsAx"
   },
   "outputs": [],
   "source": [
    "from tokenizers import Tokenizer\n",
    "\n",
    "tokenizer = Tokenizer.from_file('/content/drive/MyDrive/seq2seq model/trained_tokenizer/tokenizer.json')\n",
    "tokenizer.enable_padding(pad_to_multiple_of=25,length=25)\n",
    "tokenizer.enable_truncation(max_length=25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "executionInfo": {
     "elapsed": 5396,
     "status": "ok",
     "timestamp": 1628686888012,
     "user": {
      "displayName": "Datagram Intern",
      "photoUrl": "",
      "userId": "14028405452349474719"
     },
     "user_tz": -60
    },
    "id": "CueOsjykzzkH"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "input_sequences = np.array([i.ids for i in tokenizer.encode_batch(df['clean'])])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 16,
     "status": "ok",
     "timestamp": 1628686888012,
     "user": {
      "displayName": "Datagram Intern",
      "photoUrl": "",
      "userId": "14028405452349474719"
     },
     "user_tz": -60
    },
    "id": "Zkb8dohkTXIG",
    "outputId": "5d2c9b50-9769-4b7c-d7d4-a363043da05d"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  369,   608,  4715, ...,     0,     0,     0],\n",
       "       [  369,   608,  4715, ...,     0,     0,     0],\n",
       "       [  369,   608,  4715, ...,     0,     0,     0],\n",
       "       ...,\n",
       "       [ 1000,   727,  1254, ...,     0,     0,     0],\n",
       "       [ 5952, 18481,  9217, ...,     0,     0,     0],\n",
       "       [ 4307,  3972,   948, ...,     0,     0,     0]])"
      ]
     },
     "execution_count": 33,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "executionInfo": {
     "elapsed": 14,
     "status": "ok",
     "timestamp": 1628686888013,
     "user": {
      "displayName": "Datagram Intern",
      "photoUrl": "",
      "userId": "14028405452349474719"
     },
     "user_tz": -60
    },
    "id": "VUZafnNjBdDL"
   },
   "outputs": [],
   "source": [
    "# tokenize the inputs\n",
    "#tokenizer_inputs = Tokenizer(num_words=MAX_NUM_WORDS)\n",
    "#tokenizer_inputs.fit_on_texts(input_texts)\n",
    "#input_sequences = tokenizer_inputs.texts_to_sequences(input_texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "executionInfo": {
     "elapsed": 13,
     "status": "ok",
     "timestamp": 1628686888013,
     "user": {
      "displayName": "Datagram Intern",
      "photoUrl": "",
      "userId": "14028405452349474719"
     },
     "user_tz": -60
    },
    "id": "N1cT2rI7DEd8"
   },
   "outputs": [],
   "source": [
    "#tokenizer_inputs.texts_to_sequences(['conf sucre pcpgum mondelez hollywood'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 13,
     "status": "ok",
     "timestamp": 1628686888013,
     "user": {
      "displayName": "Datagram Intern",
      "photoUrl": "",
      "userId": "14028405452349474719"
     },
     "user_tz": -60
    },
    "id": "S-khssgfDg7n",
    "outputId": "8ebd78ce-95a3-4141-8771-e4809f7cc9c6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 30000 unique input tokens.\n"
     ]
    }
   ],
   "source": [
    "# get the word to index mapping for input language\n",
    "word2idx_inputs = tokenizer.get_vocab()\n",
    "print('Found %s unique input tokens.' % len(word2idx_inputs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "executionInfo": {
     "elapsed": 9,
     "status": "ok",
     "timestamp": 1628686888014,
     "user": {
      "displayName": "Datagram Intern",
      "photoUrl": "",
      "userId": "14028405452349474719"
     },
     "user_tz": -60
    },
    "id": "K_3hhuYgD2hj"
   },
   "outputs": [],
   "source": [
    "# determine maximum length input sequence\n",
    "#max_len_input = max(len(s) for s in input_sequences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "executionInfo": {
     "elapsed": 8,
     "status": "ok",
     "timestamp": 1628686888014,
     "user": {
      "displayName": "Datagram Intern",
      "photoUrl": "",
      "userId": "14028405452349474719"
     },
     "user_tz": -60
    },
    "id": "5VsD4ADfEOKH"
   },
   "outputs": [],
   "source": [
    "#print(max_len_input)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3zt529tcD-B7"
   },
   "source": [
    "## build the outputs tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "executionInfo": {
     "elapsed": 11449,
     "status": "ok",
     "timestamp": 1628686899456,
     "user": {
      "displayName": "Datagram Intern",
      "photoUrl": "",
      "userId": "14028405452349474719"
     },
     "user_tz": -60
    },
    "id": "vrWQCrIcEBRM"
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.text import Tokenizer as Tokenizer2\n",
    "# don't filter out special characters\n",
    "# otherwise <sos> and <eos> won't appear\n",
    "tokenizer_outputs = Tokenizer2(num_words=MAX_NUM_WORDS, filters='')\n",
    "tokenizer_outputs.fit_on_texts(target_texts + target_texts_inputs) # inefficient, oh well\n",
    "target_sequences = tokenizer_outputs.texts_to_sequences(target_texts)\n",
    "target_sequences_inputs = tokenizer_outputs.texts_to_sequences(target_texts_inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 20,
     "status": "ok",
     "timestamp": 1628686899457,
     "user": {
      "displayName": "Datagram Intern",
      "photoUrl": "",
      "userId": "14028405452349474719"
     },
     "user_tz": -60
    },
    "id": "OSnEuHraYItR",
    "outputId": "4449b150-4d87-46cf-c180-5b0fb6743d7d"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "226"
      ]
     },
     "execution_count": 40,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer_outputs.word_index[\"bike_parts\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 16,
     "status": "ok",
     "timestamp": 1628686899457,
     "user": {
      "displayName": "Datagram Intern",
      "photoUrl": "",
      "userId": "14028405452349474719"
     },
     "user_tz": -60
    },
    "id": "WWEzaWs4EShl",
    "outputId": "1e29944c-6201-4ff8-b140-d2c9ae566130"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 395 unique output tokens.\n"
     ]
    }
   ],
   "source": [
    "# get the word to index mapping for output language\n",
    "word2idx_outputs = tokenizer_outputs.word_index\n",
    "print('Found %s unique output tokens.' % len(word2idx_outputs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "executionInfo": {
     "elapsed": 13,
     "status": "ok",
     "timestamp": 1628686899458,
     "user": {
      "displayName": "Datagram Intern",
      "photoUrl": "",
      "userId": "14028405452349474719"
     },
     "user_tz": -60
    },
    "id": "kBUGKmtWEaX9"
   },
   "outputs": [],
   "source": [
    "num_words_output = len(word2idx_outputs) + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "executionInfo": {
     "elapsed": 5,
     "status": "ok",
     "timestamp": 1628686899753,
     "user": {
      "displayName": "Datagram Intern",
      "photoUrl": "",
      "userId": "14028405452349474719"
     },
     "user_tz": -60
    },
    "id": "C3rtFxXbEbcB"
   },
   "outputs": [],
   "source": [
    "# determine maximum length output sequence that will be used for the padding\n",
    "max_len_target = max(len(s) for s in target_sequences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 5,
     "status": "ok",
     "timestamp": 1628686899754,
     "user": {
      "displayName": "Datagram Intern",
      "photoUrl": "",
      "userId": "14028405452349474719"
     },
     "user_tz": -60
    },
    "id": "7VNAcuLHDpWM",
    "outputId": "074fab15-722c-4f1b-a2c5-b0f782aba70b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n"
     ]
    }
   ],
   "source": [
    "print(max_len_target)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "neI_gUn4FZxP"
   },
   "source": [
    "### Padding all the sequences and generate the encoder input and the decoder input and output "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 3797,
     "status": "ok",
     "timestamp": 1628686903547,
     "user": {
      "displayName": "Datagram Intern",
      "photoUrl": "",
      "userId": "14028405452349474719"
     },
     "user_tz": -60
    },
    "id": "kSBj1HzgFZCs",
    "outputId": "b7aa58ba-922d-4611-b6ad-977a889e62cc"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "decoder_data[0]: [  2   8 165]\n",
      "decoder_data.shape: (536437, 3)\n"
     ]
    }
   ],
   "source": [
    "# pad the sequences\n",
    "#encoder_inputs = pad_sequences(input_sequences, maxlen=max_len_input)\n",
    "#print(\"encoder_data.shape:\", encoder_inputs.shape)\n",
    "#print(\"encoder_data[0]:\", encoder_inputs[0])\n",
    "\n",
    "decoder_inputs = pad_sequences(target_sequences_inputs, maxlen=max_len_target, padding='post')\n",
    "print(\"decoder_data[0]:\", decoder_inputs[0])\n",
    "print(\"decoder_data.shape:\", decoder_inputs.shape)\n",
    "\n",
    "decoder_targets = pad_sequences(target_sequences, maxlen=max_len_target, padding='post')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 14,
     "status": "ok",
     "timestamp": 1628686903547,
     "user": {
      "displayName": "Datagram Intern",
      "photoUrl": "",
      "userId": "14028405452349474719"
     },
     "user_tz": -60
    },
    "id": "W_ZiRAVpYp11",
    "outputId": "906b549f-a4bf-4dae-d42e-b2c53db2b196"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  2,  40, 110],\n",
       "       [  2,  15, 150],\n",
       "       [  2,  15, 175],\n",
       "       [  2,   4,  79],\n",
       "       [  2,  15, 175],\n",
       "       [  2, 201, 158],\n",
       "       [  2,   8, 165],\n",
       "       [  2,  15, 175],\n",
       "       [  2,   8,  38],\n",
       "       [  2,   8,  38]], dtype=int32)"
      ]
     },
     "execution_count": 46,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "decoder_inputs[30:40]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aPQ30uIyHS5i"
   },
   "source": [
    "## Creating our Embedding Matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GICDgfZQIVUf"
   },
   "source": [
    "### Loading our Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 4383,
     "status": "ok",
     "timestamp": 1628686907919,
     "user": {
      "displayName": "Datagram Intern",
      "photoUrl": "",
      "userId": "14028405452349474719"
     },
     "user_tz": -60
    },
    "id": "Vnm1r4s_Edj1",
    "outputId": "f3937a07-76dc-4482-c0ca-051d71217b65"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading...\n",
      "From: https://drive.google.com/uc?id=12bij8nRGecBcRipDSburcpvOe6303geZ\n",
      "To: /content/Datagram_w2v_with_target.text\n",
      "340MB [00:02, 120MB/s]\n"
     ]
    }
   ],
   "source": [
    "!gdown https://drive.google.com/uc?id=12bij8nRGecBcRipDSburcpvOe6303geZ"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tqogxWKL9JPz"
   },
   "source": [
    "## Create the embedding dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 6943,
     "status": "ok",
     "timestamp": 1628686915033,
     "user": {
      "displayName": "Datagram Intern",
      "photoUrl": "",
      "userId": "14028405452349474719"
     },
     "user_tz": -60
    },
    "id": "W6IbbDXe96K5",
    "outputId": "dcae9156-9195-4d23-d650-9986780bd24d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading word vectors...\n",
      "Found 55754 word vectors.\n"
     ]
    }
   ],
   "source": [
    "import  numpy as np\n",
    "# store all the pre-trained word vectors\n",
    "print('Loading word vectors...')\n",
    "word2vec = {}\n",
    "with open(os.path.join('/content/Datagram_w2v_with_target.text')) as f:\n",
    "  # is just a space-separated text file in the format:\n",
    "  # word vec[0] vec[1] vec[2] ...\n",
    "  for line in f:\n",
    "    values = line.split()\n",
    "    word = values[0]\n",
    "    vec = np.asarray(values[1:], dtype='float32')\n",
    "    word2vec[word] = vec\n",
    "print('Found %s word vectors.' % len(word2vec))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2UhHctU8I5ol"
   },
   "source": [
    "### prepare the matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 12,
     "status": "ok",
     "timestamp": 1628686915034,
     "user": {
      "displayName": "Datagram Intern",
      "photoUrl": "",
      "userId": "14028405452349474719"
     },
     "user_tz": -60
    },
    "id": "QKy44Wi5I2gs",
    "outputId": "c5b7a39c-e361-404f-b680-19368c12c29e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filling pre-trained embeddings...\n"
     ]
    }
   ],
   "source": [
    "# prepare embedding matrix\n",
    "print('Filling pre-trained embeddings...')\n",
    "num_words = min(MAX_NUM_WORDS, len(word2idx_inputs) + 1)\n",
    "embedding_matrix = np.zeros((num_words, EMBEDDING_DIM))\n",
    "for word, i in word2idx_inputs.items():\n",
    "  if i < MAX_NUM_WORDS:\n",
    "    embedding_vector = word2vec.get(word)\n",
    "    if embedding_vector is not None:\n",
    "      # words not found in embedding index will be all zeros.\n",
    "      embedding_matrix[i] = embedding_vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 9,
     "status": "ok",
     "timestamp": 1628686915034,
     "user": {
      "displayName": "Datagram Intern",
      "photoUrl": "",
      "userId": "14028405452349474719"
     },
     "user_tz": -60
    },
    "id": "uT_md5wTJBqM",
    "outputId": "3e1fcb58-366d-4da7-fa57-dc51d81a45d2"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(30001, 512)"
      ]
     },
     "execution_count": 50,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embedding_matrix.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "esD1EmrtJdTz"
   },
   "source": [
    "## one hot encode our target data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "executionInfo": {
     "elapsed": 2064,
     "status": "ok",
     "timestamp": 1628686917094,
     "user": {
      "displayName": "Datagram Intern",
      "photoUrl": "",
      "userId": "14028405452349474719"
     },
     "user_tz": -60
    },
    "id": "fS4L_ZWKJDgI"
   },
   "outputs": [],
   "source": [
    "decoder_targets_one_hot = np.zeros(\n",
    "    shape=(\n",
    "        len(target_sequences),\n",
    "        max_len_target,\n",
    "        num_words_output\n",
    "    ),\n",
    "    dtype = \"float32\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "executionInfo": {
     "elapsed": 4405,
     "status": "ok",
     "timestamp": 1628686921497,
     "user": {
      "displayName": "Datagram Intern",
      "photoUrl": "",
      "userId": "14028405452349474719"
     },
     "user_tz": -60
    },
    "id": "OJk1QOY6JXxc"
   },
   "outputs": [],
   "source": [
    "for i,sequence in enumerate(decoder_targets):\n",
    "  for j , word in enumerate(sequence):\n",
    "    if word !=0:\n",
    "      decoder_targets_one_hot[i,j,word]=1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "epD6463EJNo9"
   },
   "source": [
    "### Building the training Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5jN7lw9LKJR2"
   },
   "source": [
    "## Encoder part"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Wq8DbWH4zAv5"
   },
   "source": [
    "## Building the Embedding layer using the pretrained vectors layer trained with word2vec "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "executionInfo": {
     "elapsed": 14,
     "status": "ok",
     "timestamp": 1628686921497,
     "user": {
      "displayName": "Datagram Intern",
      "photoUrl": "",
      "userId": "14028405452349474719"
     },
     "user_tz": -60
    },
    "id": "_p4AiycYJL-R"
   },
   "outputs": [],
   "source": [
    "embedding_layer  = Embedding(\n",
    "    num_words,\n",
    "    EMBEDDING_DIM,\n",
    "    input_length=25,\n",
    "    weights=[embedding_matrix],\n",
    "    trainable=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "executionInfo": {
     "elapsed": 14,
     "status": "ok",
     "timestamp": 1628686921498,
     "user": {
      "displayName": "Datagram Intern",
      "photoUrl": "",
      "userId": "14028405452349474719"
     },
     "user_tz": -60
    },
    "id": "mMOJOWU-3aDM"
   },
   "outputs": [],
   "source": [
    "word2id = tokenizer.get_vocab()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nH2JSOxD3Dlh"
   },
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "executionInfo": {
     "elapsed": 299,
     "status": "ok",
     "timestamp": 1628686921784,
     "user": {
      "displayName": "Datagram Intern",
      "photoUrl": "",
      "userId": "14028405452349474719"
     },
     "user_tz": -60
    },
    "id": "Nk1mYtjCJaEF"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "encoder_inputs_placeholder = Input(shape=(25,))\n",
    "x = embedding_layer(encoder_inputs_placeholder)\n",
    "encoder = Bidirectional(LSTM(\n",
    "  LATENT_DIM,\n",
    "  return_sequences=True,\n",
    "  dropout = 0.2\n",
    "))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "executionInfo": {
     "elapsed": 2577,
     "status": "ok",
     "timestamp": 1628686924359,
     "user": {
      "displayName": "Datagram Intern",
      "photoUrl": "",
      "userId": "14028405452349474719"
     },
     "user_tz": -60
    },
    "id": "RMeKxxRXKC8C"
   },
   "outputs": [],
   "source": [
    "encoder_outputs = encoder(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NUWHbR0EKNGj"
   },
   "source": [
    "### Decoder part"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "executionInfo": {
     "elapsed": 15,
     "status": "ok",
     "timestamp": 1628686924359,
     "user": {
      "displayName": "Datagram Intern",
      "photoUrl": "",
      "userId": "14028405452349474719"
     },
     "user_tz": -60
    },
    "id": "i6umakrLKGmD"
   },
   "outputs": [],
   "source": [
    "decoder_inputs_placeholder = Input(shape=(max_len_target,))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 14,
     "status": "ok",
     "timestamp": 1628686924360,
     "user": {
      "displayName": "Datagram Intern",
      "photoUrl": "",
      "userId": "14028405452349474719"
     },
     "user_tz": -60
    },
    "id": "npqkq2idZIpA",
    "outputId": "ca4d722c-e3a0-4186-cd76-7087c4ff1da7"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 58,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_len_target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 12,
     "status": "ok",
     "timestamp": 1628686924360,
     "user": {
      "displayName": "Datagram Intern",
      "photoUrl": "",
      "userId": "14028405452349474719"
     },
     "user_tz": -60
    },
    "id": "kkX5Yt-EDIjs",
    "outputId": "43441886-0386-4d6b-bf36-bc149ce03a5e"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "395"
      ]
     },
     "execution_count": 59,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(word2idx_outputs) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "executionInfo": {
     "elapsed": 8,
     "status": "ok",
     "timestamp": 1628686924360,
     "user": {
      "displayName": "Datagram Intern",
      "photoUrl": "",
      "userId": "14028405452349474719"
     },
     "user_tz": -60
    },
    "id": "WSQGI7LlCUBo"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "U5YVOzL_gAl1"
   },
   "source": [
    "# prepare embedding matrix\n",
    "print('Filling pre-trained embeddings...')\n",
    "num_words = min(MAX_NUM_WORDS, len(word2idx_outputs) + 1)\n",
    "embedding_matrix_output = np.zeros((num_words, EMBEDDING_DIM))\n",
    "for word, i in word2idx_outputs.items():\n",
    "  if i < MAX_NUM_WORDS:\n",
    "    embedding_vector = word2vec.get(word)\n",
    "    if embedding_vector is not None:\n",
    "      # words not found in embedding index will be all zeros.\n",
    "      embedding_matrix_output[i] = embedding_vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "executionInfo": {
     "elapsed": 8,
     "status": "ok",
     "timestamp": 1628686924361,
     "user": {
      "displayName": "Datagram Intern",
      "photoUrl": "",
      "userId": "14028405452349474719"
     },
     "user_tz": -60
    },
    "id": "P33QZA87KWQi"
   },
   "outputs": [],
   "source": [
    "decoder_embedding = Embedding(num_words_output, EMBEDDING_DIM,trainable=True)\n",
    "decoder_inputs_x = decoder_embedding(decoder_inputs_placeholder)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BFNUCoVPKrnS"
   },
   "source": [
    "### Building the attention layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "executionInfo": {
     "elapsed": 8,
     "status": "ok",
     "timestamp": 1628686924361,
     "user": {
      "displayName": "Datagram Intern",
      "photoUrl": "",
      "userId": "14028405452349474719"
     },
     "user_tz": -60
    },
    "id": "7ciBIHjBKqTX"
   },
   "outputs": [],
   "source": [
    "attn_repeat_layer = RepeatVector(25)\n",
    "attn_concat_layer = Concatenate(axis=-1)\n",
    "attn_dense1 = Dense(128, activation='tanh')\n",
    "attn_dense2 = Dense(1, activation=Softmax(axis=1))\n",
    "attn_dot = Dot(axes=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "executionInfo": {
     "elapsed": 8,
     "status": "ok",
     "timestamp": 1628686924361,
     "user": {
      "displayName": "Datagram Intern",
      "photoUrl": "",
      "userId": "14028405452349474719"
     },
     "user_tz": -60
    },
    "id": "ZwzVhU8JK3fq"
   },
   "outputs": [],
   "source": [
    "def one_step_attention(h, st_1):\n",
    "  # h = h(1), ..., h(Tx), shape = (Tx, LATENT_DIM * 2)\n",
    "  # st_1 = s(t-1), shape = (LATENT_DIM_DECODER,)\n",
    "\n",
    "  # copy s(t-1) Tx times\n",
    "  # now shape = (Tx, LATENT_DIM_DECODER)\n",
    "  st_1 = attn_repeat_layer(st_1)\n",
    "\n",
    "  # Concatenate all h(t)'s with s(t-1)\n",
    "  # Now of shape (Tx, LATENT_DIM_DECODER + LATENT_DIM * 2)\n",
    "  x = attn_concat_layer([h, st_1])\n",
    "\n",
    "  # Neural net first layer\n",
    "  x = attn_dense1(x)\n",
    "\n",
    "  # Neural net second layer with special softmax over time\n",
    "  alphas = attn_dense2(x)\n",
    "\n",
    "  # \"Dot\" the alphas and the h's\n",
    "  # Remember a.dot(b) = sum over a[t] * b[t]\n",
    "  context = attn_dot([alphas, h])\n",
    "\n",
    "  return context"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CTLvl8SzLA66"
   },
   "source": [
    "### define the rest of the decoder (after attention)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "executionInfo": {
     "elapsed": 9,
     "status": "ok",
     "timestamp": 1628686924362,
     "user": {
      "displayName": "Datagram Intern",
      "photoUrl": "",
      "userId": "14028405452349474719"
     },
     "user_tz": -60
    },
    "id": "U_Deq8a8K5YT"
   },
   "outputs": [],
   "source": [
    "# define the rest of the decoder (after attention)\n",
    "decoder_lstm = LSTM(LATENT_DIM_DECODER, return_state=True)\n",
    "decoder_dense = Dense(num_words_output, activation='softmax')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "executionInfo": {
     "elapsed": 8,
     "status": "ok",
     "timestamp": 1628686924362,
     "user": {
      "displayName": "Datagram Intern",
      "photoUrl": "",
      "userId": "14028405452349474719"
     },
     "user_tz": -60
    },
    "id": "mhABObDmLPyh"
   },
   "outputs": [],
   "source": [
    "initial_s = Input(shape=(LATENT_DIM_DECODER,), name='s0')\n",
    "initial_c = Input(shape=(LATENT_DIM_DECODER,), name='c0')\n",
    "context_last_word_concat_layer = Concatenate(axis=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "executionInfo": {
     "elapsed": 8,
     "status": "ok",
     "timestamp": 1628686924362,
     "user": {
      "displayName": "Datagram Intern",
      "photoUrl": "",
      "userId": "14028405452349474719"
     },
     "user_tz": -60
    },
    "id": "Z6lpzS95LRTs"
   },
   "outputs": [],
   "source": [
    "s = initial_s\n",
    "c = initial_c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "executionInfo": {
     "elapsed": 2083,
     "status": "ok",
     "timestamp": 1628686926437,
     "user": {
      "displayName": "Datagram Intern",
      "photoUrl": "",
      "userId": "14028405452349474719"
     },
     "user_tz": -60
    },
    "id": "4Ww076JlLTn4"
   },
   "outputs": [],
   "source": [
    "# collect outputs in a list at first\n",
    "outputs = []\n",
    "for t in range(max_len_target): # Ty times\n",
    "  # get the context using attention\n",
    "  context = one_step_attention(encoder_outputs, s)\n",
    "\n",
    "  # we need a different layer for each time step\n",
    "  selector = Lambda(lambda x: x[:, t:t+1])\n",
    "  xt = selector(decoder_inputs_x)\n",
    "  \n",
    "  # combine \n",
    "  decoder_lstm_input = context_last_word_concat_layer([context, xt])\n",
    "\n",
    "  # pass the combined [context, last word] into the LSTM\n",
    "  # along with [s, c]\n",
    "  # get the new [s, c] and output\n",
    "  o, s, c = decoder_lstm(decoder_lstm_input, initial_state=[s, c])\n",
    "\n",
    "  # final dense layer to get next word prediction\n",
    "  decoder_outputs = decoder_dense(o)\n",
    "  outputs.append(decoder_outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "executionInfo": {
     "elapsed": 10,
     "status": "ok",
     "timestamp": 1628686926437,
     "user": {
      "displayName": "Datagram Intern",
      "photoUrl": "",
      "userId": "14028405452349474719"
     },
     "user_tz": -60
    },
    "id": "tIssMa-GLrW5"
   },
   "outputs": [],
   "source": [
    "import tensorflow.keras.backend as K\n",
    "def stack_and_transpose(x):\n",
    "  # x is a list of length T, each element is a batch_size x output_vocab_size tensor\n",
    "  x = K.stack(x) # is now T x batch_size x output_vocab_size tensor\n",
    "  x = K.permute_dimensions(x, pattern=(1, 0, 2)) # is now batch_size x T x output_vocab_size\n",
    "  return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "executionInfo": {
     "elapsed": 8,
     "status": "ok",
     "timestamp": 1628686926437,
     "user": {
      "displayName": "Datagram Intern",
      "photoUrl": "",
      "userId": "14028405452349474719"
     },
     "user_tz": -60
    },
    "id": "B71bqIXMLuNw"
   },
   "outputs": [],
   "source": [
    "# make it a layer\n",
    "stacker = Lambda(stack_and_transpose)\n",
    "outputs = stacker(outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "executionInfo": {
     "elapsed": 8,
     "status": "ok",
     "timestamp": 1628686926438,
     "user": {
      "displayName": "Datagram Intern",
      "photoUrl": "",
      "userId": "14028405452349474719"
     },
     "user_tz": -60
    },
    "id": "22PQYBTMLwIv"
   },
   "outputs": [],
   "source": [
    "# create the model\n",
    "model = Model(\n",
    "  inputs=[\n",
    "    encoder_inputs_placeholder,\n",
    "    decoder_inputs_placeholder,\n",
    "    initial_s, \n",
    "    initial_c,\n",
    "  ],\n",
    "  outputs=outputs\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "executionInfo": {
     "elapsed": 7,
     "status": "ok",
     "timestamp": 1628686926438,
     "user": {
      "displayName": "Datagram Intern",
      "photoUrl": "",
      "userId": "14028405452349474719"
     },
     "user_tz": -60
    },
    "id": "NsVzK896cYpL"
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.optimizers import Adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "executionInfo": {
     "elapsed": 7,
     "status": "ok",
     "timestamp": 1628686926439,
     "user": {
      "displayName": "Datagram Intern",
      "photoUrl": "",
      "userId": "14028405452349474719"
     },
     "user_tz": -60
    },
    "id": "3fBD4AmGahI2"
   },
   "outputs": [],
   "source": [
    "def custom_loss(y_true, y_pred):\n",
    "  # both are of shape N x T x K\n",
    "  mask = K.cast(y_true > 0, dtype='float32')\n",
    "  out = mask * y_true * K.log(y_pred)\n",
    "  return -K.sum(out) / K.sum(mask)\n",
    "\n",
    "\n",
    "def acc(y_true, y_pred):\n",
    "  # both are of shape N x T x K\n",
    "  targ = K.argmax(y_true, axis=-1)\n",
    "  pred = K.argmax(y_pred, axis=-1)\n",
    "  correct = K.cast(K.equal(targ, pred), dtype='float32')\n",
    "\n",
    "  # 0 is padding, don't include those\n",
    "  mask = K.cast(K.greater(targ, 0), dtype='float32')\n",
    "  n_correct = K.sum(mask * correct)\n",
    "  n_total = K.sum(mask)\n",
    "  return n_correct / n_total\n",
    "\n",
    "def new_acc(y_true, y_pred):\n",
    "  # both are of shape N x T x K\n",
    "  targ = K.argmax(y_true, axis=-1)\n",
    "  pred = K.argmax(y_pred, axis=-1)\n",
    "  correct = K.cast(K.equal(targ, pred), dtype='float32')\n",
    "  pcname_mask = tf.expand_dims(K.cast(K.greater(correct[:,0],0),dtype='float'),axis=-1)\n",
    "  correct = correct*pcname_mask \n",
    "  # 0 is padding, don't include those\n",
    "  mask = K.cast(K.greater(targ, 0), dtype='float32')\n",
    "  n_correct = K.sum(mask * correct)\n",
    "  n_total = K.sum(mask)\n",
    "  return n_correct / n_total\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "executionInfo": {
     "elapsed": 7,
     "status": "ok",
     "timestamp": 1628686926439,
     "user": {
      "displayName": "Datagram Intern",
      "photoUrl": "",
      "userId": "14028405452349474719"
     },
     "user_tz": -60
    },
    "id": "RmPQjKvdL6PT"
   },
   "outputs": [],
   "source": [
    "# compile the model\n",
    "model.compile(optimizer=Adam(0.001), loss=custom_loss, metrics=[new_acc])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "executionInfo": {
     "elapsed": 3767,
     "status": "ok",
     "timestamp": 1628686930199,
     "user": {
      "displayName": "Datagram Intern",
      "photoUrl": "",
      "userId": "14028405452349474719"
     },
     "user_tz": -60
    },
    "id": "MPDGyzWMhjGM"
   },
   "outputs": [],
   "source": [
    "z = np.zeros((len(input_sequences), LATENT_DIM_DECODER)) # initial [s, c]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "executionInfo": {
     "elapsed": 20,
     "status": "ok",
     "timestamp": 1628686930199,
     "user": {
      "displayName": "Datagram Intern",
      "photoUrl": "",
      "userId": "14028405452349474719"
     },
     "user_tz": -60
    },
    "id": "AMvvddirW5Fi"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "executionInfo": {
     "elapsed": 20,
     "status": "ok",
     "timestamp": 1628686930200,
     "user": {
      "displayName": "Datagram Intern",
      "photoUrl": "",
      "userId": "14028405452349474719"
     },
     "user_tz": -60
    },
    "id": "7GctFUtolt9_"
   },
   "outputs": [],
   "source": [
    "dataset = tf.data.Dataset.from_tensor_slices(((input_sequences, decoder_inputs, z, z), decoder_targets_one_hot)).shuffle(10000).batch(BATCH_SIZE).prefetch(tf.data.AUTOTUNE).cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "executionInfo": {
     "elapsed": 19,
     "status": "ok",
     "timestamp": 1628686930200,
     "user": {
      "displayName": "Datagram Intern",
      "photoUrl": "",
      "userId": "14028405452349474719"
     },
     "user_tz": -60
    },
    "id": "jUlkpwf2dGsp"
   },
   "outputs": [],
   "source": [
    "len_dataset = len(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 19,
     "status": "ok",
     "timestamp": 1628686930200,
     "user": {
      "displayName": "Datagram Intern",
      "photoUrl": "",
      "userId": "14028405452349474719"
     },
     "user_tz": -60
    },
    "id": "y41xeR2ndKNj",
    "outputId": "047267c5-7006-4876-9c1c-307854f31ec7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1048\n"
     ]
    }
   ],
   "source": [
    "print(len_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "executionInfo": {
     "elapsed": 17,
     "status": "ok",
     "timestamp": 1628686930201,
     "user": {
      "displayName": "Datagram Intern",
      "photoUrl": "",
      "userId": "14028405452349474719"
     },
     "user_tz": -60
    },
    "id": "Hl2xUSjzcwel"
   },
   "outputs": [],
   "source": [
    "training_dataset = dataset.take(int(len_dataset*0.8))\n",
    "validation_dataset = dataset.skip(int(len_dataset*0.8)).take(int(len_dataset*0.1))\n",
    "test_dataset =  dataset.skip(int(len_dataset*0.9)).take(int(len_dataset*0.1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 17,
     "status": "ok",
     "timestamp": 1628686930201,
     "user": {
      "displayName": "Datagram Intern",
      "photoUrl": "",
      "userId": "14028405452349474719"
     },
     "user_tz": -60
    },
    "id": "ybBMGo6em7Cl",
    "outputId": "3270c008-d24f-4653-dd76-28e47dfe0b39"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            [(None, 25)]         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding (Embedding)           (None, 25, 512)      15360512    input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "s0 (InputLayer)                 [(None, 1024)]       0                                            \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional (Bidirectional)   (None, 25, 2048)     12591104    embedding[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "repeat_vector (RepeatVector)    (None, 25, 1024)     0           s0[0][0]                         \n",
      "                                                                 lstm_1[0][1]                     \n",
      "                                                                 lstm_1[1][1]                     \n",
      "__________________________________________________________________________________________________\n",
      "concatenate (Concatenate)       (None, 25, 3072)     0           bidirectional[0][0]              \n",
      "                                                                 repeat_vector[0][0]              \n",
      "                                                                 bidirectional[0][0]              \n",
      "                                                                 repeat_vector[1][0]              \n",
      "                                                                 bidirectional[0][0]              \n",
      "                                                                 repeat_vector[2][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dense (Dense)                   (None, 25, 128)      393344      concatenate[0][0]                \n",
      "                                                                 concatenate[1][0]                \n",
      "                                                                 concatenate[2][0]                \n",
      "__________________________________________________________________________________________________\n",
      "input_2 (InputLayer)            [(None, 3)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 25, 1)        129         dense[0][0]                      \n",
      "                                                                 dense[1][0]                      \n",
      "                                                                 dense[2][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "embedding_1 (Embedding)         (None, 3, 512)       202752      input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dot (Dot)                       (None, 1, 2048)      0           dense_1[0][0]                    \n",
      "                                                                 bidirectional[0][0]              \n",
      "                                                                 dense_1[1][0]                    \n",
      "                                                                 bidirectional[0][0]              \n",
      "                                                                 dense_1[2][0]                    \n",
      "                                                                 bidirectional[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "lambda (Lambda)                 (None, 1, 512)       0           embedding_1[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)     (None, 1, 2560)      0           dot[0][0]                        \n",
      "                                                                 lambda[0][0]                     \n",
      "                                                                 dot[1][0]                        \n",
      "                                                                 lambda_1[0][0]                   \n",
      "                                                                 dot[2][0]                        \n",
      "                                                                 lambda_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "c0 (InputLayer)                 [(None, 1024)]       0                                            \n",
      "__________________________________________________________________________________________________\n",
      "lstm_1 (LSTM)                   [(None, 1024), (None 14684160    concatenate_1[0][0]              \n",
      "                                                                 s0[0][0]                         \n",
      "                                                                 c0[0][0]                         \n",
      "                                                                 concatenate_1[1][0]              \n",
      "                                                                 lstm_1[0][1]                     \n",
      "                                                                 lstm_1[0][2]                     \n",
      "                                                                 concatenate_1[2][0]              \n",
      "                                                                 lstm_1[1][1]                     \n",
      "                                                                 lstm_1[1][2]                     \n",
      "__________________________________________________________________________________________________\n",
      "lambda_1 (Lambda)               (None, 1, 512)       0           embedding_1[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "lambda_2 (Lambda)               (None, 1, 512)       0           embedding_1[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "dense_2 (Dense)                 (None, 396)          405900      lstm_1[0][0]                     \n",
      "                                                                 lstm_1[1][0]                     \n",
      "                                                                 lstm_1[2][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "lambda_3 (Lambda)               (None, 3, 396)       0           dense_2[0][0]                    \n",
      "                                                                 dense_2[1][0]                    \n",
      "                                                                 dense_2[2][0]                    \n",
      "==================================================================================================\n",
      "Total params: 43,637,901\n",
      "Trainable params: 43,637,901\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "#@title Titre par défaut\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 117345,
     "status": "ok",
     "timestamp": 1628687047533,
     "user": {
      "displayName": "Datagram Intern",
      "photoUrl": "",
      "userId": "14028405452349474719"
     },
     "user_tz": -60
    },
    "id": "0-EYbEkY1gSX",
    "outputId": "2195ff01-fe13-49f0-e291-ff194260bd53"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "104/104 [==============================] - 91s 636ms/step - loss: 5.9805 - new_acc: 0.0030\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[5.980542182922363, 0.00302984775044024]"
      ]
     },
     "execution_count": 79,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(test_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "executionInfo": {
     "elapsed": 20,
     "status": "ok",
     "timestamp": 1628687047533,
     "user": {
      "displayName": "Datagram Intern",
      "photoUrl": "",
      "userId": "14028405452349474719"
     },
     "user_tz": -60
    },
    "id": "94Nx4UaK_NQY"
   },
   "outputs": [],
   "source": [
    "#len(validation_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "executionInfo": {
     "elapsed": 20,
     "status": "ok",
     "timestamp": 1628687047534,
     "user": {
      "displayName": "Datagram Intern",
      "photoUrl": "",
      "userId": "14028405452349474719"
     },
     "user_tz": -60
    },
    "id": "7Yt8jMX9_Oxg"
   },
   "outputs": [],
   "source": [
    "#len(test_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "executionInfo": {
     "elapsed": 19,
     "status": "ok",
     "timestamp": 1628687047534,
     "user": {
      "displayName": "Datagram Intern",
      "photoUrl": "",
      "userId": "14028405452349474719"
     },
     "user_tz": -60
    },
    "id": "mYv-5VwqqWuM"
   },
   "outputs": [],
   "source": [
    "#np.array(list(training_dataset.as_numpy_iterator())).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "executionInfo": {
     "elapsed": 18,
     "status": "ok",
     "timestamp": 1628687047534,
     "user": {
      "displayName": "Datagram Intern",
      "photoUrl": "",
      "userId": "14028405452349474719"
     },
     "user_tz": -60
    },
    "id": "y_L90mcHqsII"
   },
   "outputs": [],
   "source": [
    "#np.array(list(test_dataset.as_numpy_iterator())).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "executionInfo": {
     "elapsed": 19,
     "status": "ok",
     "timestamp": 1628687047535,
     "user": {
      "displayName": "Datagram Intern",
      "photoUrl": "",
      "userId": "14028405452349474719"
     },
     "user_tz": -60
    },
    "id": "VQq-JkDterTe"
   },
   "outputs": [],
   "source": [
    "#training_dataset.take(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "executionInfo": {
     "elapsed": 18,
     "status": "ok",
     "timestamp": 1628687047535,
     "user": {
      "displayName": "Datagram Intern",
      "photoUrl": "",
      "userId": "14028405452349474719"
     },
     "user_tz": -60
    },
    "id": "haDMIDHvcwiX"
   },
   "outputs": [],
   "source": [
    "#test_dataset.take(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "executionInfo": {
     "elapsed": 18,
     "status": "ok",
     "timestamp": 1628687047535,
     "user": {
      "displayName": "Datagram Intern",
      "photoUrl": "",
      "userId": "14028405452349474719"
     },
     "user_tz": -60
    },
    "id": "Ei0jn0nmaZVR"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "executionInfo": {
     "elapsed": 18,
     "status": "ok",
     "timestamp": 1628687047536,
     "user": {
      "displayName": "Datagram Intern",
      "photoUrl": "",
      "userId": "14028405452349474719"
     },
     "user_tz": -60
    },
    "id": "gDMnfgbK4Iet"
   },
   "outputs": [],
   "source": [
    "early_stopping_callback = tf.keras.callbacks.EarlyStopping(monitor='new_acc', patience=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "executionInfo": {
     "elapsed": 19,
     "status": "ok",
     "timestamp": 1628687047538,
     "user": {
      "displayName": "Datagram Intern",
      "photoUrl": "",
      "userId": "14028405452349474719"
     },
     "user_tz": -60
    },
    "id": "MrKzb-mVFGDG"
   },
   "outputs": [],
   "source": [
    "checkpoint_filepath = os.path.join(\"/content/drive/MyDrive/seq2seq model\", 'ckpt', 'epoch: {epoch:02d} - accuracy: {new_acc:.03} - val_accuracy: {val_new_acc:.2f}.h5')\n",
    "model_checkpoint_callback = tf.keras.callbacks.ModelCheckpoint(\n",
    "    filepath=checkpoint_filepath,\n",
    "    save_weights_only=True,\n",
    "    monitor='new_acc',\n",
    "    mode='max',\n",
    "    save_best_only=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "executionInfo": {
     "elapsed": 19,
     "status": "ok",
     "timestamp": 1628687047538,
     "user": {
      "displayName": "Datagram Intern",
      "photoUrl": "",
      "userId": "14028405452349474719"
     },
     "user_tz": -60
    },
    "id": "x_P6tWBaayLr"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1588687,
     "status": "ok",
     "timestamp": 1628688636206,
     "user": {
      "displayName": "Datagram Intern",
      "photoUrl": "",
      "userId": "14028405452349474719"
     },
     "user_tz": -60
    },
    "id": "Z-jFL5ZmMWK4",
    "outputId": "53179935-9c93-4ede-d059-3c0e55afe000"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "786/786 [==============================] - 1587s 2s/step - loss: 0.1693 - new_acc: 0.9564 - val_loss: 0.0070 - val_new_acc: 0.9989\n"
     ]
    }
   ],
   "source": [
    "r = model.fit(\n",
    "  [input_sequences, decoder_inputs, z, z], decoder_targets_one_hot,\n",
    "  epochs=1,\n",
    "  batch_size = BATCH_SIZE,\n",
    "  validation_split=0.25,\n",
    "  callbacks=[early_stopping_callback,model_checkpoint_callback]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 12,
     "status": "ok",
     "timestamp": 1628688636209,
     "user": {
      "displayName": "Datagram Intern",
      "photoUrl": "",
      "userId": "14028405452349474719"
     },
     "user_tz": -60
    },
    "id": "TnofhE-jqyKe",
    "outputId": "406644d7-8480-4c01-f49d-06eaaf655a31"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f1a3871c4d0>"
      ]
     },
     "execution_count": 89,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 10,
     "status": "ok",
     "timestamp": 1628688636210,
     "user": {
      "displayName": "Datagram Intern",
      "photoUrl": "",
      "userId": "14028405452349474719"
     },
     "user_tz": -60
    },
    "id": "2kF0s0UBqTbf",
    "outputId": "d46a4ba1-ecb9-470f-c448-99212e44645d"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'loss': [0.16932989656925201],\n",
       " 'new_acc': [0.9564334750175476],\n",
       " 'val_loss': [0.006965183187276125],\n",
       " 'val_new_acc': [0.9989189505577087]}"
      ]
     },
     "execution_count": 90,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "r.history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 111585,
     "status": "ok",
     "timestamp": 1628688747790,
     "user": {
      "displayName": "Datagram Intern",
      "photoUrl": "",
      "userId": "14028405452349474719"
     },
     "user_tz": -60
    },
    "id": "8bLrPq6IL3cU",
    "outputId": "33b61429-545d-47e4-e3de-42b5d5b2796c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "104/104 [==============================] - 93s 639ms/step - loss: 0.0024 - new_acc: 0.9996\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.002422923920676112, 0.9995743632316589]"
      ]
     },
     "execution_count": 91,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(test_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 14,
     "status": "ok",
     "timestamp": 1628688747790,
     "user": {
      "displayName": "Datagram Intern",
      "photoUrl": "",
      "userId": "14028405452349474719"
     },
     "user_tz": -60
    },
    "id": "16AqcDNNdSq5",
    "outputId": "ef031e4f-1abc-49a2-bbc0-44fc21c51af7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            [(None, 25)]         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding (Embedding)           (None, 25, 512)      15360512    input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "s0 (InputLayer)                 [(None, 1024)]       0                                            \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional (Bidirectional)   (None, 25, 2048)     12591104    embedding[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "repeat_vector (RepeatVector)    (None, 25, 1024)     0           s0[0][0]                         \n",
      "                                                                 lstm_1[0][1]                     \n",
      "                                                                 lstm_1[1][1]                     \n",
      "__________________________________________________________________________________________________\n",
      "concatenate (Concatenate)       (None, 25, 3072)     0           bidirectional[0][0]              \n",
      "                                                                 repeat_vector[0][0]              \n",
      "                                                                 bidirectional[0][0]              \n",
      "                                                                 repeat_vector[1][0]              \n",
      "                                                                 bidirectional[0][0]              \n",
      "                                                                 repeat_vector[2][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dense (Dense)                   (None, 25, 128)      393344      concatenate[0][0]                \n",
      "                                                                 concatenate[1][0]                \n",
      "                                                                 concatenate[2][0]                \n",
      "__________________________________________________________________________________________________\n",
      "input_2 (InputLayer)            [(None, 3)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 25, 1)        129         dense[0][0]                      \n",
      "                                                                 dense[1][0]                      \n",
      "                                                                 dense[2][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "embedding_1 (Embedding)         (None, 3, 512)       202752      input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dot (Dot)                       (None, 1, 2048)      0           dense_1[0][0]                    \n",
      "                                                                 bidirectional[0][0]              \n",
      "                                                                 dense_1[1][0]                    \n",
      "                                                                 bidirectional[0][0]              \n",
      "                                                                 dense_1[2][0]                    \n",
      "                                                                 bidirectional[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "lambda (Lambda)                 (None, 1, 512)       0           embedding_1[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)     (None, 1, 2560)      0           dot[0][0]                        \n",
      "                                                                 lambda[0][0]                     \n",
      "                                                                 dot[1][0]                        \n",
      "                                                                 lambda_1[0][0]                   \n",
      "                                                                 dot[2][0]                        \n",
      "                                                                 lambda_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "c0 (InputLayer)                 [(None, 1024)]       0                                            \n",
      "__________________________________________________________________________________________________\n",
      "lstm_1 (LSTM)                   [(None, 1024), (None 14684160    concatenate_1[0][0]              \n",
      "                                                                 s0[0][0]                         \n",
      "                                                                 c0[0][0]                         \n",
      "                                                                 concatenate_1[1][0]              \n",
      "                                                                 lstm_1[0][1]                     \n",
      "                                                                 lstm_1[0][2]                     \n",
      "                                                                 concatenate_1[2][0]              \n",
      "                                                                 lstm_1[1][1]                     \n",
      "                                                                 lstm_1[1][2]                     \n",
      "__________________________________________________________________________________________________\n",
      "lambda_1 (Lambda)               (None, 1, 512)       0           embedding_1[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "lambda_2 (Lambda)               (None, 1, 512)       0           embedding_1[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "dense_2 (Dense)                 (None, 396)          405900      lstm_1[0][0]                     \n",
      "                                                                 lstm_1[1][0]                     \n",
      "                                                                 lstm_1[2][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "lambda_3 (Lambda)               (None, 3, 396)       0           dense_2[0][0]                    \n",
      "                                                                 dense_2[1][0]                    \n",
      "                                                                 dense_2[2][0]                    \n",
      "==================================================================================================\n",
      "Total params: 43,637,901\n",
      "Trainable params: 43,637,901\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "executionInfo": {
     "elapsed": 269,
     "status": "ok",
     "timestamp": 1628689199860,
     "user": {
      "displayName": "Datagram Intern",
      "photoUrl": "",
      "userId": "14028405452349474719"
     },
     "user_tz": -60
    },
    "id": "IGVmwVQXVbWd"
   },
   "outputs": [],
   "source": [
    "encoder_model = Model(encoder_inputs_placeholder, encoder_outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {
    "executionInfo": {
     "elapsed": 245,
     "status": "ok",
     "timestamp": 1628689200355,
     "user": {
      "displayName": "Datagram Intern",
      "photoUrl": "",
      "userId": "14028405452349474719"
     },
     "user_tz": -60
    },
    "id": "cATbhTVkViCP"
   },
   "outputs": [],
   "source": [
    "encoder_model = Model(encoder_inputs_placeholder, encoder_outputs)\n",
    "\n",
    "# next we define a T=1 decoder model\n",
    "encoder_outputs_as_input = Input(shape=(25, LATENT_DIM * 2,))\n",
    "decoder_inputs_single = Input(shape=(1,)) \n",
    "decoder_inputs_single_x = decoder_embedding(decoder_inputs_single)\n",
    "\n",
    "# no need to loop over attention steps this time because there is only one step\n",
    "context = one_step_attention(encoder_outputs_as_input, initial_s)\n",
    "\n",
    "# combine context with last word\n",
    "decoder_lstm_input = context_last_word_concat_layer([context, decoder_inputs_single_x])\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# lstm and final dense\n",
    "o, s, c = decoder_lstm(decoder_lstm_input, initial_state=[initial_s, initial_c])\n",
    "decoder_outputs = decoder_dense(o)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "executionInfo": {
     "elapsed": 3,
     "status": "ok",
     "timestamp": 1628689201218,
     "user": {
      "displayName": "Datagram Intern",
      "photoUrl": "",
      "userId": "14028405452349474719"
     },
     "user_tz": -60
    },
    "id": "P7lV1bLQVkt2"
   },
   "outputs": [],
   "source": [
    "decoder_model = Model(\n",
    "  inputs=[\n",
    "    decoder_inputs_single,\n",
    "    encoder_outputs_as_input,\n",
    "    initial_s, \n",
    "    initial_c\n",
    "  ],\n",
    "  outputs=[decoder_outputs, s, c]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {
    "executionInfo": {
     "elapsed": 4,
     "status": "ok",
     "timestamp": 1628689202018,
     "user": {
      "displayName": "Datagram Intern",
      "photoUrl": "",
      "userId": "14028405452349474719"
     },
     "user_tz": -60
    },
    "id": "C-Yeo6vdVnGl"
   },
   "outputs": [],
   "source": [
    "idx2word_intput = {v:k for k, v in word2id.items()}\n",
    "idx2word_trans = {v:k for k, v in word2idx_outputs.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {
    "executionInfo": {
     "elapsed": 2,
     "status": "ok",
     "timestamp": 1628689203078,
     "user": {
      "displayName": "Datagram Intern",
      "photoUrl": "",
      "userId": "14028405452349474719"
     },
     "user_tz": -60
    },
    "id": "-kU2oUe5QH6P"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {
    "executionInfo": {
     "elapsed": 2,
     "status": "ok",
     "timestamp": 1628689203379,
     "user": {
      "displayName": "Datagram Intern",
      "photoUrl": "",
      "userId": "14028405452349474719"
     },
     "user_tz": -60
    },
    "id": "UwLStDggVpoe"
   },
   "outputs": [],
   "source": [
    "def decode_sequence(input_seq):\n",
    "  # Encode the input as state vectors.\n",
    "  enc_out = encoder_model.predict(input_seq)\n",
    "\n",
    "  # Generate empty target sequence of length 1.\n",
    "  target_seq = np.zeros((1, 1))\n",
    "  \n",
    "  # Populate the first character of target sequence with the start character.\n",
    "  # NOTE: tokenizer lower-cases all words\n",
    "  target_seq[0, 0] = word2idx_outputs['<sos>']\n",
    "\n",
    "  # if we get this we break\n",
    "  eos = word2idx_outputs['<eos>']\n",
    "\n",
    "\n",
    "  # [s, c] will be updated in each loop iteration\n",
    "  s = np.zeros((1, LATENT_DIM_DECODER))\n",
    "  c = np.zeros((1, LATENT_DIM_DECODER))\n",
    "\n",
    "\n",
    "  # Create the translation\n",
    "  output_sentence = []\n",
    "  for _ in range(max_len_target):\n",
    "    o, s, c = decoder_model.predict([target_seq, enc_out, s, c])\n",
    "        \n",
    "\n",
    "    # Get next word\n",
    "    idx = np.argmax(o.flatten())\n",
    "\n",
    "    # End sentence of EOS\n",
    "    if eos == idx:\n",
    "      break\n",
    "\n",
    "    word = ''\n",
    "    if idx > 0:\n",
    "      word = idx2word_trans[idx]\n",
    "      output_sentence.append(word)\n",
    "\n",
    "    # Update the decoder input\n",
    "    # which is just the word just generated\n",
    "    target_seq[0, 0] = idx\n",
    "\n",
    "  return '-->'.join(output_sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 225,
     "status": "ok",
     "timestamp": 1628689205342,
     "user": {
      "displayName": "Datagram Intern",
      "photoUrl": "",
      "userId": "14028405452349474719"
     },
     "user_tz": -60
    },
    "id": "MiSIslNOq_t8",
    "outputId": "30c7258b-2f90-4160-e29c-3a73f71ee210"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<TakeDataset shapes: (((None, 25), (None, 3), (None, 1024), (None, 1024)), (None, 3, 396)), types: ((tf.int64, tf.int32, tf.float64, tf.float64), tf.float32)>"
      ]
     },
     "execution_count": 105,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_dataset.take(0).take(0).take(0).take(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 450009,
     "status": "ok",
     "timestamp": 1628691755777,
     "user": {
      "displayName": "Datagram Intern",
      "photoUrl": "",
      "userId": "14028405452349474719"
     },
     "user_tz": -60
    },
    "id": "JTcPxpMyVwaM",
    "outputId": "0caf499d-b358-40e5-ffe2-7274d9f0e4b0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "i:  435562\n",
      "[[8589 8621  958 2984  886 5380  958    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0]]\n",
      "-\n",
      "Input sentence: tommee tippee recharge poubelle  couches twist  recharge\n",
      "Predicted translation: emballages_menagers-->sacs_poubelles\n",
      "Actual translation: puericulture accessoires_puericulture <eos>\n",
      "Continue? [Y/n]n\n"
     ]
    }
   ],
   "source": [
    "while True:\n",
    "  # Do some test translations\n",
    "  i = np.random.choice(len(input_texts))\n",
    "  print(\"i: \" ,i)\n",
    "  input_seq = input_sequences[i:i+1]\n",
    "  print(input_seq)\n",
    "  translation = decode_sequence(input_seq)\n",
    "  print('-')\n",
    "  print('Input sentence:', input_texts[i])\n",
    "  print('Predicted translation:', translation)\n",
    "  print('Actual translation:', target_texts[i])\n",
    "\n",
    "  ans = input(\"Continue? [Y/n]\")\n",
    "  if ans and ans.lower().startswith('n'):\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 358,
     "status": "aborted",
     "timestamp": 1628688748701,
     "user": {
      "displayName": "Datagram Intern",
      "photoUrl": "",
      "userId": "14028405452349474719"
     },
     "user_tz": -60
    },
    "id": "NBE09iRu1Qzs"
   },
   "outputs": [],
   "source": [
    "def get_prediction(text):\n",
    "  return decode_sequence(pad_sequences(tokenizer_inputs.texts_to_sequences([text]),maxlen=max_len_input))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 360,
     "status": "aborted",
     "timestamp": 1628688748703,
     "user": {
      "displayName": "Datagram Intern",
      "photoUrl": "",
      "userId": "14028405452349474719"
     },
     "user_tz": -60
    },
    "id": "a27x7pMrMqZp"
   },
   "outputs": [],
   "source": [
    "get_prediction(\"nestea peche blanche pet\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "n9E4iwNcGfj0"
   },
   "source": [
    "# Saving the Encoder and the decoder model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1102,
     "status": "ok",
     "timestamp": 1628691814847,
     "user": {
      "displayName": "Datagram Intern",
      "photoUrl": "",
      "userId": "14028405452349474719"
     },
     "user_tz": -60
    },
    "id": "1AOGfgWoV01K",
    "outputId": "b91aa5eb-03f5-45e8-a565-2ca782444ab2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    }
   ],
   "source": [
    "encoder_model.save(\"/content/drive/MyDrive/seq2seq model/seq2seq_model/encoder.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 271,
     "status": "ok",
     "timestamp": 1628691782530,
     "user": {
      "displayName": "Datagram Intern",
      "photoUrl": "",
      "userId": "14028405452349474719"
     },
     "user_tz": -60
    },
    "id": "-sUBUIxfuo4Z",
    "outputId": "8bb871a7-8c51-4611-aba1-12b1cdae9df0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    }
   ],
   "source": [
    "decoder_model.save('/content/drive/MyDrive/seq2seq model/seq2seq_model/decoder.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "26e5lhSPGlXS"
   },
   "source": [
    "# Saving the input and output tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {
    "executionInfo": {
     "elapsed": 237,
     "status": "ok",
     "timestamp": 1628690754058,
     "user": {
      "displayName": "Datagram Intern",
      "photoUrl": "",
      "userId": "14028405452349474719"
     },
     "user_tz": -60
    },
    "id": "fuNohDMy_g34"
   },
   "outputs": [],
   "source": [
    "#import io,json\n",
    "#tokenizer_json = tokenizer_inputs.to_json()\n",
    "#with io.open('/content/drive/MyDrive/seq2seq model/seq2seq_model/tokenizer/input_tokenizer.json', 'w', encoding='utf-8') as f:\n",
    "    #f.write(json.dumps(tokenizer_json, ensure_ascii=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {
    "executionInfo": {
     "elapsed": 202,
     "status": "ok",
     "timestamp": 1628691788130,
     "user": {
      "displayName": "Datagram Intern",
      "photoUrl": "",
      "userId": "14028405452349474719"
     },
     "user_tz": -60
    },
    "id": "W7gZdp1qAjkP"
   },
   "outputs": [],
   "source": [
    "\n",
    "tokenizer_json = tokenizer_outputs.to_json()\n",
    "with io.open('/content/drive/MyDrive/seq2seq model/seq2seq_model/tokenizer/output_tokenizer.json', 'w', encoding='utf-8') as f:\n",
    "    f.write(json.dumps(tokenizer_json, ensure_ascii=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 362,
     "status": "aborted",
     "timestamp": 1628688748706,
     "user": {
      "displayName": "Datagram Intern",
      "photoUrl": "",
      "userId": "14028405452349474719"
     },
     "user_tz": -60
    },
    "id": "oKcv6yG1Ay45"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "TPU",
  "colab": {
   "collapsed_sections": [],
   "machine_shape": "hm",
   "name": "Seq2seq.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
